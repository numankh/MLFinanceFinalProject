{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c3d512f",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576833bf",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3698336",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using the following machine learning models for making predictions for the following portfolio optimization models:\n",
    "- Mean-variance optimization (chapter 7 of Bodie, Investment book)\n",
    "- Index model (chapter 8 of Bodie, Investment book)\n",
    "- Capital asset pricing model (chapter 9 of Bodie, Investment book)\n",
    "- Arbitrage pricing theory and multifactor model (chapter 10 of Bodie,\n",
    "Investment book)\n",
    "- Equity valuation model (chapter 18 of Bodie, Investment book)\n",
    "- Black Litterman model (chapter 24 of Bodie, Investment book)\n",
    "- Algorithmic trading (this could be restricted to the last month)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5455474e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e998cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  10 of 10 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>BRK-B</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>META</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>UNH</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-06-27</th>\n",
       "      <td>188.059998</td>\n",
       "      <td>129.179993</td>\n",
       "      <td>335.339996</td>\n",
       "      <td>118.330002</td>\n",
       "      <td>287.049988</td>\n",
       "      <td>334.570007</td>\n",
       "      <td>418.760010</td>\n",
       "      <td>250.210007</td>\n",
       "      <td>482.559998</td>\n",
       "      <td>104.550003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28</th>\n",
       "      <td>189.250000</td>\n",
       "      <td>129.039993</td>\n",
       "      <td>334.149994</td>\n",
       "      <td>120.180000</td>\n",
       "      <td>285.290009</td>\n",
       "      <td>335.850006</td>\n",
       "      <td>411.170013</td>\n",
       "      <td>256.239990</td>\n",
       "      <td>474.450012</td>\n",
       "      <td>105.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29</th>\n",
       "      <td>189.589996</td>\n",
       "      <td>127.900002</td>\n",
       "      <td>336.910004</td>\n",
       "      <td>119.099998</td>\n",
       "      <td>281.529999</td>\n",
       "      <td>335.049988</td>\n",
       "      <td>408.220001</td>\n",
       "      <td>257.500000</td>\n",
       "      <td>476.440002</td>\n",
       "      <td>106.699997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>193.970001</td>\n",
       "      <td>130.360001</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>119.699997</td>\n",
       "      <td>286.980011</td>\n",
       "      <td>340.540009</td>\n",
       "      <td>423.019989</td>\n",
       "      <td>261.769989</td>\n",
       "      <td>480.640015</td>\n",
       "      <td>107.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-03</th>\n",
       "      <td>192.460007</td>\n",
       "      <td>130.220001</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>119.900002</td>\n",
       "      <td>286.019989</td>\n",
       "      <td>337.989990</td>\n",
       "      <td>424.130005</td>\n",
       "      <td>279.820007</td>\n",
       "      <td>477.880005</td>\n",
       "      <td>107.459999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AAPL        AMZN       BRK-B       GOOGL        META  \\\n",
       "Date                                                                     \n",
       "2023-06-27  188.059998  129.179993  335.339996  118.330002  287.049988   \n",
       "2023-06-28  189.250000  129.039993  334.149994  120.180000  285.290009   \n",
       "2023-06-29  189.589996  127.900002  336.910004  119.099998  281.529999   \n",
       "2023-06-30  193.970001  130.360001  341.000000  119.699997  286.980011   \n",
       "2023-07-03  192.460007  130.220001  342.000000  119.900002  286.019989   \n",
       "\n",
       "                  MSFT        NVDA        TSLA         UNH         XOM  \n",
       "Date                                                                    \n",
       "2023-06-27  334.570007  418.760010  250.210007  482.559998  104.550003  \n",
       "2023-06-28  335.850006  411.170013  256.239990  474.450012  105.400002  \n",
       "2023-06-29  335.049988  408.220001  257.500000  476.440002  106.699997  \n",
       "2023-06-30  340.540009  423.019989  261.769989  480.640015  107.250000  \n",
       "2023-07-03  337.989990  424.130005  279.820007  477.880005  107.459999  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "from pypfopt import plotting, EfficientFrontier, objective_functions, expected_returns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pypfopt import BlackLittermanModel, black_litterman, risk_models\n",
    "\n",
    "\n",
    "tickers = [\"AAPL\", \"AMZN\", \"BRK-B\", \"GOOGL\", \"META\", \"MSFT\", \"NVDA\", \"TSLA\", \"UNH\", \"XOM\"]\n",
    "portfolio_data = yf.download(tickers, period=\"5y\")\n",
    "portfolio_data = portfolio_data[\"Adj Close\"]\n",
    "portfolio_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "937b3971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2023-06-27    4378.410156\n",
       "2023-06-28    4376.859863\n",
       "2023-06-29    4396.439941\n",
       "2023-06-30    4450.379883\n",
       "2023-07-03    4455.589844\n",
       "Name: Adj Close, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_index_ticker = \"^GSPC\"  # S&P 500 index\n",
    "market_index_data = yf.download(market_index_ticker, period=\"5y\")\n",
    "market_index_data = market_index_data[\"Adj Close\"]\n",
    "market_index_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c777d4",
   "metadata": {},
   "source": [
    "## Mean Variance Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0515cab1",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88edd1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL     0.025210\n",
      "AMZN     2.252283\n",
      "BRK-B    0.187033\n",
      "GOOGL    1.554961\n",
      "META     0.417067\n",
      "MSFT     0.038136\n",
      "NVDA     0.013240\n",
      "TSLA     3.328888\n",
      "UNH     -0.230505\n",
      "XOM      0.144229\n",
      "Name: mkt, dtype: float64\n",
      "OrderedDict([('AAPL', 0.14446), ('AMZN', 0.00734), ('BRK-B', 0.13015), ('GOOGL', 0.04641), ('META', 0.09304), ('MSFT', 0.14107), ('NVDA', 0.14968), ('TSLA', 0.00304), ('UNH', 0.14817), ('XOM', 0.13665)])\n",
      "Expected annual return: 0.1585062746466839\n",
      "Annual volatility: 0.11130273901640701\n",
      "Sharpe ratio: 1.2444102981712504\n"
     ]
    }
   ],
   "source": [
    "future_prices = {}\n",
    "for ticker in tickers:\n",
    "    data = portfolio_data[ticker].tolist()\n",
    "    # Dependent variable - 10 consecutive days of stock prices\n",
    "    dev_x = [data[i:i+10] for i in range(len(data)-20)]\n",
    "    \n",
    "    # Independent variable - stock price 10th day into the future\n",
    "    dev_y = [data[i+10] for i in range(10,len(data)-10)]\n",
    "    \n",
    "    test = [data[i:i+10] for i in range(len(data)-20,len(data)-10)]\n",
    "    \n",
    "    reg = RandomForestRegressor()\n",
    "    reg.fit(dev_x,dev_y)\n",
    "    \n",
    "    # Predict stock price for 10 future days\n",
    "    pred = reg.predict(test)\n",
    "    future_prices[ticker] = pred\n",
    "\n",
    "future_prices = pd.DataFrame(future_prices)\n",
    "# Construct covariance matrix of future stock prices\n",
    "S = risk_models.CovarianceShrinkage(future_prices).ledoit_wolf()\n",
    "\n",
    "# Use capm to find expected returns on future prices\n",
    "mu = expected_returns.capm_return(future_prices)\n",
    "print(mu)\n",
    "\n",
    "# Do mean variance optimization using efficient frontier\n",
    "ef = EfficientFrontier(mu, S)\n",
    "ef.min_volatility()\n",
    "weights = ef.clean_weights()\n",
    "print(weights)\n",
    "# weights = ef.max_sharpe(risk_free_rate=0.02)\n",
    "# cleaned_weights = ef.clean_weights()\n",
    "# print(cleaned_weights)\n",
    "\n",
    "ret, volatility, sharpe_ratio = ef.portfolio_performance()\n",
    "print(\"Expected annual return:\", ret)\n",
    "print(\"Annual volatility:\", volatility)\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd90b9",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13084abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL     0.036081\n",
      "AMZN    -0.105575\n",
      "BRK-B   -0.004571\n",
      "GOOGL   -0.130701\n",
      "META     0.003582\n",
      "MSFT    -0.023083\n",
      "NVDA    -0.061680\n",
      "TSLA    -0.156760\n",
      "UNH     -0.037295\n",
      "XOM      0.000436\n",
      "Name: mkt, dtype: float64\n",
      "OrderedDict([('AAPL', 0.21053), ('AMZN', 0.01913), ('BRK-B', 0.16), ('GOOGL', 0.027), ('META', 0.17512), ('MSFT', 0.10298), ('NVDA', 0.01529), ('TSLA', 0.0442), ('UNH', 0.10212), ('XOM', 0.14363)])\n",
      "Expected annual return: -0.012051418502632178\n",
      "Annual volatility: 0.012313234762764323\n",
      "Sharpe ratio: -2.603005556229371\n"
     ]
    }
   ],
   "source": [
    "future_prices = {}\n",
    "for ticker in tickers:\n",
    "    data = portfolio_data[ticker].tolist()\n",
    "    dev_x = [data[i:i+10] for i in range(len(data)-20)]\n",
    "    dev_y = [data[i+10] for i in range(10, len(data)-10)]\n",
    "    test = [data[i:i+10] for i in range(len(data)-20, len(data)-10)]\n",
    "    \n",
    "    reg = SVR()\n",
    "    reg.fit(dev_x, dev_y)\n",
    "    \n",
    "    pred = reg.predict(test)\n",
    "    future_prices[ticker] = pred\n",
    "\n",
    "future_prices = pd.DataFrame(future_prices)\n",
    "\n",
    "S = risk_models.CovarianceShrinkage(future_prices).ledoit_wolf()\n",
    "mu = expected_returns.capm_return(future_prices)\n",
    "print(mu)\n",
    "\n",
    "ef = EfficientFrontier(mu, S)\n",
    "ef.min_volatility()\n",
    "weights = ef.clean_weights()\n",
    "print(weights)\n",
    "\n",
    "\n",
    "ret, volatility, sharpe_ratio = ef.portfolio_performance()\n",
    "print(\"Expected annual return:\", ret)\n",
    "print(\"Annual volatility:\", volatility)\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894acc7c",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fbad704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL    -0.051072\n",
      "AMZN     0.005034\n",
      "BRK-B   -0.013537\n",
      "GOOGL   -0.046004\n",
      "META    -0.056244\n",
      "MSFT    -0.066116\n",
      "NVDA    -0.273637\n",
      "TSLA    -0.415881\n",
      "UNH     -0.012283\n",
      "XOM      0.012491\n",
      "Name: mkt, dtype: float64\n",
      "OrderedDict([('AAPL', 0.08875), ('AMZN', 0.1699), ('BRK-B', 0.26304), ('GOOGL', 0.06651), ('META', 0.09893), ('MSFT', 0.06343), ('NVDA', 0.0), ('TSLA', 0.0), ('UNH', 0.11485), ('XOM', 0.13459)])\n",
      "Expected annual return: -0.019785228834557224\n",
      "Annual volatility: 0.05025352960990399\n",
      "Sharpe ratio: -0.7916902383452948\n"
     ]
    }
   ],
   "source": [
    "future_prices = {}\n",
    "for ticker in tickers:\n",
    "    data = portfolio_data[ticker].tolist()\n",
    "    dev_x = [data[i:i+10] for i in range(len(data)-20)]\n",
    "    dev_y = [data[i+10] for i in range(10, len(data)-10)]\n",
    "    test = [data[i:i+10] for i in range(len(data)-20, len(data)-10)]\n",
    "    \n",
    "    reg = MLPRegressor(hidden_layer_sizes=(100,100), random_state=42)  # You can adjust the hidden_layer_sizes and other parameters as needed\n",
    "    reg.fit(dev_x, dev_y)\n",
    "    \n",
    "    pred = reg.predict(test)\n",
    "    future_prices[ticker] = pred\n",
    "\n",
    "future_prices = pd.DataFrame(future_prices)\n",
    "\n",
    "S = risk_models.CovarianceShrinkage(future_prices).ledoit_wolf()\n",
    "mu = expected_returns.capm_return(future_prices)\n",
    "print(mu)\n",
    "\n",
    "ef = EfficientFrontier(mu, S)\n",
    "ef.min_volatility()\n",
    "weights = ef.clean_weights()\n",
    "print(weights)\n",
    "\n",
    "ret, volatility, sharpe_ratio = ef.portfolio_performance()\n",
    "print(\"Expected annual return:\", ret)\n",
    "print(\"Annual volatility:\", volatility)\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e43441",
   "metadata": {},
   "source": [
    "## Index model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5840faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleIndexModel:\n",
    "    def __init__(self, tickers, market_index_data, portfolio_data, reg_model):\n",
    "        self.tickers = tickers\n",
    "        self.market_index_data = market_index_data\n",
    "        self.portfolio_data = portfolio_data\n",
    "        self.reg_model = reg_model\n",
    "        self.returns = {}\n",
    "        self.beta = {}\n",
    "        self.alpha = {}\n",
    "        self.residual_variance = {}\n",
    "\n",
    "    def calculate_returns(self):\n",
    "        # Returns of stocks and market\n",
    "        self.returns = {\"MARKET\": ((self.market_index_data / self.market_index_data.shift(1)) - 1).dropna().tolist()}\n",
    "        for ticker in self.tickers:\n",
    "            self.returns[ticker] = ((self.portfolio_data[ticker] / self.portfolio_data[ticker].shift(1))-1).dropna().tolist()\n",
    "\n",
    "    def fit_regression(self):\n",
    "        # Forecast market\n",
    "        market_x = [self.returns[\"MARKET\"][i:i+10] for i in range(len(self.returns[\"MARKET\"])-20)]\n",
    "        market_y = [self.returns[\"MARKET\"][i+10] for i in range(10, len(self.returns[\"MARKET\"])-10)]\n",
    "        market_test = [self.returns[\"MARKET\"][i:i+10] \n",
    "                       for i in range(len(self.returns[\"MARKET\"])-20, len(self.returns[\"MARKET\"])-10)]\n",
    "\n",
    "        reg = self.reg_model\n",
    "        reg.fit(market_x, market_y)\n",
    "        market_future = reg.predict(market_test)\n",
    "\n",
    "        # Forecast each stock\n",
    "        for ticker in self.tickers:\n",
    "            stock_x = [self.returns[ticker][i:i+10] for i in range(len(self.returns[ticker])-20)]\n",
    "            stock_y = [self.returns[ticker][i+10] for i in range(10, len(self.returns[ticker])-10)]\n",
    "            stock_test = [self.returns[ticker][i:i+10]\n",
    "                          for i in range(len(self.returns[ticker])-20, len(self.returns[ticker])-10)]\n",
    "\n",
    "            reg = self.reg_model\n",
    "            reg.fit(stock_x, stock_y)\n",
    "            stock_future = reg.predict(stock_test)\n",
    "\n",
    "            single_index_reg = LinearRegression()\n",
    "            single_index_reg.fit(np.array(market_future).reshape(-1, 1), y=stock_future)\n",
    "\n",
    "            self.beta[ticker] = single_index_reg.coef_[0]\n",
    "            self.alpha[ticker] = single_index_reg.intercept_\n",
    "\n",
    "            y_pred = single_index_reg.predict(np.array(self.returns[\"MARKET\"]).reshape(-1, 1))\n",
    "            residuals = self.returns[ticker] - y_pred\n",
    "            self.residual_variance[ticker] = np.var(residuals)\n",
    "\n",
    "    def optimize_portfolio(self):\n",
    "        # Compute the initial position of each security\n",
    "        weights = {ticker: self.alpha[ticker] / self.residual_variance[ticker] for ticker in self.tickers}\n",
    "        total_weight = sum(weights.values())\n",
    "        weights = {ticker: weight / total_weight for ticker, weight in weights.items()}\n",
    "\n",
    "        # Compute the alpha of the active portfolio\n",
    "        alpha_portfolio = sum(weights[ticker] * self.alpha[ticker] for ticker in self.tickers)\n",
    "\n",
    "        # Compute the residual variance of the active portfolio\n",
    "        residual_variance_portfolio = sum((weights[ticker] ** 2) * self.residual_variance[ticker] for ticker in self.tickers)\n",
    "\n",
    "        # Compute the initial position in the active portfolio\n",
    "        residual_variance_market = 0.0114  # Variance of S&P 500\n",
    "        risk_premium_market = 0.056\n",
    "        initial_position_portfolio = (alpha_portfolio * residual_variance_market) / (residual_variance_portfolio * risk_premium_market)\n",
    "\n",
    "        # Compute the beta of the active portfolio\n",
    "        beta_portfolio = sum(weights[ticker] * self.beta[ticker] for ticker in self.tickers)\n",
    "\n",
    "        # Adjust the initial position in the active portfolio\n",
    "        adjusted_position_portfolio = initial_position_portfolio / (1 + (1 - beta_portfolio) * initial_position_portfolio)\n",
    "\n",
    "        # Optimal risky portfolio now has weights\n",
    "        final_weight_market = 1 - adjusted_position_portfolio\n",
    "        weights = {ticker: weight * adjusted_position_portfolio for ticker, weight in weights.items()}\n",
    "\n",
    "        # Calculate the risk premium of the portfolio\n",
    "        risk_premium_portfolio = (final_weight_market + adjusted_position_portfolio * beta_portfolio) * risk_premium_market + adjusted_position_portfolio * alpha_portfolio\n",
    "\n",
    "        # Compute the variance of the portfolio\n",
    "        portfolio_variance = (final_weight_market + adjusted_position_portfolio * beta_portfolio) ** 2 * residual_variance_market + adjusted_position_portfolio ** 2 * residual_variance_portfolio\n",
    "\n",
    "        # Calculate the Sharpe ratio\n",
    "        sharpe_ratio = risk_premium_portfolio / (portfolio_variance ** 0.5)\n",
    "\n",
    "        return weights, final_weight_market, sharpe_ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdc52d5",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c642ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Final Weights:\n",
      "Weight Market S&P: 0.5863947154779436\n",
      "Weights: {'AAPL': 0.26245855216495373, 'AMZN': -0.24351280116629392, 'BRK-B': 0.05099943749882177, 'GOOGL': 0.17223330565613174, 'META': 0.015777155097337677, 'MSFT': 0.20589381728954562, 'NVDA': 0.13104113814112353, 'TSLA': 0.07097496736933147, 'UNH': -0.011992229889740521, 'XOM': -0.24026805763915465}\n",
      "------------------------------\n",
      "Sharpe ratio: 0.5750544045291437\n"
     ]
    }
   ],
   "source": [
    "reg_model = RandomForestRegressor()\n",
    "portfolio = SingleIndexModel(tickers, market_index_data, portfolio_data, reg_model)\n",
    "portfolio.calculate_returns()\n",
    "portfolio.fit_regression()\n",
    "weights, final_weight_market, sharpe_ratio = portfolio.optimize_portfolio()\n",
    "print(\"------------------------------\")\n",
    "print(\"Final Weights:\")\n",
    "print(\"Weight Market S&P:\", final_weight_market)\n",
    "print(f\"Weights: {weights}\")\n",
    "print(\"------------------------------\")\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa76324",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55b45800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Final Weights:\n",
      "Weight Market S&P: 1.6320028230417156\n",
      "Weights: {'AAPL': -0.12279014064991728, 'AMZN': -0.0461725280570754, 'BRK-B': -0.13287934469957183, 'GOOGL': -0.03694513352444664, 'META': -0.20714365403244403, 'MSFT': -0.09824409442752727, 'NVDA': 0.007111067632432751, 'TSLA': -0.061080731833562635, 'UNH': 0.04178252368762089, 'XOM': 0.02435921286277579}\n",
      "------------------------------\n",
      "Sharpe ratio: -2.6875784968770726\n"
     ]
    }
   ],
   "source": [
    "reg_model = SVR()\n",
    "portfolio = SingleIndexModel(tickers, market_index_data, portfolio_data, reg_model)\n",
    "portfolio.calculate_returns()\n",
    "portfolio.fit_regression()\n",
    "weights, final_weight_market, sharpe_ratio = portfolio.optimize_portfolio()\n",
    "print(\"------------------------------\")\n",
    "print(\"Final Weights:\")\n",
    "print(\"Weight Market S&P:\", final_weight_market)\n",
    "print(f\"Weights: {weights}\")\n",
    "print(\"------------------------------\")\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8fade6",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e57a097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Final Weights:\n",
      "Weight Market S&P: -2.344827058474747\n",
      "Weights: {'AAPL': 1.361267585370607, 'AMZN': -0.20477682489179236, 'BRK-B': 0.5025486018685142, 'GOOGL': 0.8856925565602729, 'META': 0.12421059997387304, 'MSFT': 0.30407503866548125, 'NVDA': 0.3163740951493393, 'TSLA': -0.09759375316058574, 'UNH': 0.06859656568202628, 'XOM': 0.08443259325701072}\n",
      "------------------------------\n",
      "Sharpe ratio: 0.6987993476646619\n"
     ]
    }
   ],
   "source": [
    "reg_model = MLPRegressor(hidden_layer_sizes=(100,100))\n",
    "portfolio = SingleIndexModel(tickers, market_index_data, portfolio_data, reg_model)\n",
    "portfolio.calculate_returns()\n",
    "portfolio.fit_regression()\n",
    "weights, final_weight_market, sharpe_ratio = portfolio.optimize_portfolio()\n",
    "print(\"------------------------------\")\n",
    "print(\"Final Weights:\")\n",
    "print(\"Weight Market S&P:\", final_weight_market)\n",
    "print(f\"Weights: {weights}\")\n",
    "print(\"------------------------------\")\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db4f9d8",
   "metadata": {},
   "source": [
    "### Capital asset pricing model (CAPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37b915a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "Non-linear ML model: RandomForestRegressor()\n",
      "OrderedDict([('AAPL', 0.01074), ('AMZN', 0.0), ('BRK-B', 0.0), ('GOOGL', 0.0), ('META', 0.0), ('MSFT', 0.0), ('NVDA', 0.15156), ('TSLA', 0.8377), ('UNH', 0.0), ('XOM', 0.0)])\n",
      "Expected annual return: None\n",
      "Annual volatility: 2.5132886377335244\n",
      "Sharpe ratio: None\n",
      "----------------------------------------------------\n",
      "Non-linear ML model: GradientBoostingRegressor()\n",
      "OrderedDict([('AAPL', 0.18022), ('AMZN', 0.0), ('BRK-B', 0.0), ('GOOGL', 0.0), ('META', 0.0), ('MSFT', 0.07494), ('NVDA', 0.24377), ('TSLA', 0.50106), ('UNH', 0.0), ('XOM', 0.0)])\n",
      "Expected annual return: None\n",
      "Annual volatility: 3.7654381293505743\n",
      "Sharpe ratio: None\n",
      "----------------------------------------------------\n",
      "Non-linear ML model: MLPRegressor(hidden_layer_sizes=(100, 100))\n",
      "OrderedDict([('AAPL', 0.11639), ('AMZN', 0.08814), ('BRK-B', 0.07595), ('GOOGL', 0.07992), ('META', 0.09114), ('MSFT', 0.11192), ('NVDA', 0.119), ('TSLA', 0.12906), ('UNH', 0.10198), ('XOM', 0.08649)])\n",
      "Expected annual return: None\n",
      "Annual volatility: 6.513106475469537\n",
      "Sharpe ratio: None\n"
     ]
    }
   ],
   "source": [
    "reg_models = [RandomForestRegressor(), GradientBoostingRegressor(), MLPRegressor(hidden_layer_sizes=(100, 100))]\n",
    "\n",
    "for reg_model in reg_models:\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(f\"Non-linear ML model: {reg_model}\")\n",
    "    \n",
    "    returns = {\"MARKET\": ((market_index_data / market_index_data.shift(1)) - 1).dropna().tolist()}\n",
    "    for ticker in tickers:\n",
    "        returns[ticker] = ((portfolio_data[ticker] / portfolio_data[ticker].shift(1))-1).dropna().tolist()\n",
    "\n",
    "\n",
    "    market_x = [returns[\"MARKET\"][i:i+10] for i in range(len(returns[\"MARKET\"])-20)]\n",
    "    market_y = [returns[\"MARKET\"][i+10] for i in range(10, len(returns[\"MARKET\"])-10)]\n",
    "    market_test = [returns[\"MARKET\"][i:i+10]\n",
    "                   for i in range(len(returns[\"MARKET\"])-20, len(returns[\"MARKET\"])-10)]\n",
    "\n",
    "    reg = MLPRegressor(hidden_layer_sizes=(100,100))\n",
    "    reg.fit(market_x, market_y)\n",
    "    market_future = reg.predict(market_test)\n",
    "#     print(market_future)\n",
    "\n",
    "    future_returns = {}\n",
    "    for ticker in tickers:\n",
    "        single_index_reg = Ridge()\n",
    "        single_index_reg.fit(np.array(returns[\"MARKET\"]).reshape(-1, 1), y=returns[ticker])\n",
    "        future_returns[ticker] = single_index_reg.predict(np.array(market_future).reshape(-1, 1))\n",
    "\n",
    "    future_returns = pd.DataFrame(future_returns)\n",
    "#     print(future_returns)\n",
    "\n",
    "    S = risk_models.CovarianceShrinkage(future_returns).ledoit_wolf()\n",
    "    ef = EfficientFrontier(None, S)\n",
    "    ef.min_volatility()\n",
    "    weights = ef.clean_weights()\n",
    "    print(weights)\n",
    "\n",
    "\n",
    "    ret, volatility, sharpe_ratio = ef.portfolio_performance()\n",
    "    print(\"Expected annual return:\", ret)\n",
    "    print(\"Annual volatility:\", volatility)\n",
    "    print(\"Sharpe ratio:\", sharpe_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a626fe31",
   "metadata": {},
   "source": [
    "### Arbitrage pricing theory and multifactor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a133b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_models = [RandomForestRegressor(), GradientBoostingRegressor(), MLPRegressor(hidden_layer_sizes=(100, 100))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8884ea50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "Non-linear ML model: RandomForestRegressor()\n",
      "[*********************100%***********************]  3 of 3 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/risk_models.py:70: UserWarning: The covariance matrix is non positive semidefinite. Amending eigenvalues.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/risk_models.py:89: UserWarning: Could not fix matrix. Please try a different risk model.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/efficient_frontier/efficient_frontier.py:441: UserWarning: The risk_free_rate provided to portfolio_performance is different to the one used by max_sharpe. Using the previous value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('AAPL', 0.0), ('AMZN', 0.0), ('BRK-B', 0.0), ('GOOGL', 0.0), ('META', 0.0), ('MSFT', 0.0), ('NVDA', 0.79289), ('TSLA', 0.20711), ('UNH', 0.0), ('XOM', 0.0)])\n",
      "Expected annual return: 0.0019685787880436576\n",
      "Annual volatility: 0.5284216589090845\n",
      "Sharpe ratio: 0.0037253938305779276\n",
      "----------------------------------------------------\n",
      "Non-linear ML model: GradientBoostingRegressor()\n",
      "[*********************100%***********************]  3 of 3 completed\n",
      "OrderedDict([('AAPL', 0.0), ('AMZN', 0.01476), ('BRK-B', 0.0), ('GOOGL', 0.0), ('META', 0.08275), ('MSFT', 0.0), ('NVDA', 0.01637), ('TSLA', 0.14981), ('UNH', 0.00107), ('XOM', 0.73524)])\n",
      "Expected annual return: 0.0015471497362253724\n",
      "Annual volatility: 1.3198975029657125\n",
      "Sharpe ratio: 0.0011721741519694073\n",
      "----------------------------------------------------\n",
      "Non-linear ML model: MLPRegressor(hidden_layer_sizes=(100, 100))\n",
      "[                       0%                       ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/risk_models.py:70: UserWarning: The covariance matrix is non positive semidefinite. Amending eigenvalues.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/efficient_frontier/efficient_frontier.py:441: UserWarning: The risk_free_rate provided to portfolio_performance is different to the one used by max_sharpe. Using the previous value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed\n",
      "OrderedDict([('AAPL', 0.0), ('AMZN', 0.01272), ('BRK-B', 0.0), ('GOOGL', 0.0), ('META', 0.0), ('MSFT', 0.0), ('NVDA', 0.54068), ('TSLA', 0.09575), ('UNH', 0.0), ('XOM', 0.35085)])\n",
      "Expected annual return: 0.0025876506348077102\n",
      "Annual volatility: 0.41439956613930745\n",
      "Sharpe ratio: 0.006244337220029394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/risk_models.py:70: UserWarning: The covariance matrix is non positive semidefinite. Amending eigenvalues.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/efficient_frontier/efficient_frontier.py:441: UserWarning: The risk_free_rate provided to portfolio_performance is different to the one used by max_sharpe. Using the previous value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for reg in reg_models:\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(f\"Non-linear ML model: {reg}\")\n",
    "    \n",
    "    # Fetch historical data for the macroeconomic factors\n",
    "    factor_tickers = ['SPY', 'TLT', 'BND']\n",
    "    factor_data = yf.download(factor_tickers, period=\"5y\")\n",
    "    factor_data = factor_data['Adj Close']\n",
    "\n",
    "    # Calculate the returns for the S&P and Treasury bond factors\n",
    "    factor_returns = factor_data.pct_change().dropna()\n",
    "    spy_returns = factor_returns['SPY']\n",
    "    tlt_returns = factor_returns['TLT']\n",
    "    bnd_returns = factor_returns['BND']\n",
    "\n",
    "    # FACTOR 1\n",
    "    # Train ML model to predict future price of S&P market factors\n",
    "    bnd_x = [bnd_returns[i:i+10] for i in range(len(bnd_returns)-20)]\n",
    "    bnd_y = [bnd_returns[i+10] for i in range(10, len(bnd_returns)-10)]\n",
    "\n",
    "    bnd_test = [bnd_returns[i:i+10]\n",
    "                   for i in range(len(bnd_returns)-20, len(bnd_returns)-10)]\n",
    "    reg.fit(bnd_x, bnd_y)\n",
    "    bnd_future = reg.predict(bnd_test)\n",
    "\n",
    "    # FACTOR 2\n",
    "    # Train ML model to predict future price of S&P market factors\n",
    "    spy_x = [spy_returns[i:i+10] for i in range(len(spy_returns)-20)]\n",
    "    spy_y = [spy_returns[i+10] for i in range(10, len(spy_returns)-10)]\n",
    "\n",
    "    spy_test = [spy_returns[i:i+10]\n",
    "                   for i in range(len(spy_returns)-20, len(spy_returns)-10)]\n",
    "    reg.fit(spy_x, spy_y)\n",
    "    spy_future = reg.predict(spy_test)\n",
    "\n",
    "    # FACTOR 3\n",
    "    # Train ML model to predict future price of Treasury Bond ETF factors\n",
    "    tlt_x = [tlt_returns[i:i+10] for i in range(len(tlt_returns)-20)]\n",
    "    tlt_y = [tlt_returns[i+10] for i in range(10, len(tlt_returns)-10)]\n",
    "\n",
    "    tlt_test = [tlt_returns[i:i+10]\n",
    "                   for i in range(len(tlt_returns)-20, len(tlt_returns)-10)]\n",
    "\n",
    "    reg.fit(tlt_x, tlt_y)\n",
    "    tlt_future = reg.predict(tlt_test)\n",
    "\n",
    "    # FACTOR 4\n",
    "    # GDP Price of USA for past 5 years\n",
    "\n",
    "    # US GDP per capita Prices of last 5 years\n",
    "    GDP_prices = {\n",
    "            2018: 59607,\n",
    "            2019: 60698,\n",
    "            2020: 58453,\n",
    "            2021: 61855,\n",
    "            2022: 62551,\n",
    "            2023: 63451 # Forecast data also available online\n",
    "        }\n",
    "\n",
    "    # Normalize the GDP values as it will make the other factors irrelevant as it is very large\n",
    "    values = list(GDP_prices.values())\n",
    "    values_array = [[value] for value in values]\n",
    "    scaler = StandardScaler()\n",
    "    scaled_values = scaler.fit_transform(values_array)\n",
    "    scaled_values = scaled_values.flatten()\n",
    "    scaled_GDP_prices = {year: scaled_value for year, scaled_value in zip(GDP_prices.keys(), scaled_values)}\n",
    "\n",
    "    # print(scaled_GDP_prices)\n",
    "\n",
    "    for index, row in factor_returns.iterrows():\n",
    "        # Extract the year from the date\n",
    "        year = index.year\n",
    "\n",
    "        # Fill the 'GDP' column with the corresponding GDP price based on the year\n",
    "        factor_returns.at[index, 'GDP'] = scaled_GDP_prices.get(year)\n",
    "\n",
    "    future_factors = {'BND': bnd_future, 'SPY': spy_future, 'TLT': tlt_future, 'GDP': [scaled_GDP_prices.get(2023)]*10}\n",
    "    future_factors = pd.DataFrame(future_factors)\n",
    "\n",
    "    returns = {}\n",
    "    future_returns = {}\n",
    "    for ticker in tickers:\n",
    "        stock_returns = ((portfolio_data[ticker] / portfolio_data[ticker].shift(1))-1).dropna().tolist()\n",
    "        returns[ticker] = stock_returns\n",
    "\n",
    "        single_index_reg = Ridge()\n",
    "        single_index_reg.fit(factor_returns, stock_returns)\n",
    "        stock_future = single_index_reg.predict(future_factors)\n",
    "        future_returns[ticker] = stock_future\n",
    "    #     print(\"Coefficients: \", single_index_reg.coef_)\n",
    "\n",
    "    future_returns = pd.DataFrame(future_returns)\n",
    "    # print(future_returns)\n",
    "\n",
    "    S = risk_models.sample_cov(future_returns)\n",
    "    # print(S)\n",
    "\n",
    "\n",
    "#     print(future_returns.mean())\n",
    "    ef = EfficientFrontier(future_returns.mean(), S)\n",
    "    weights = ef.max_sharpe(risk_free_rate=0.0)\n",
    "    cleaned_weights = ef.clean_weights()\n",
    "    print(cleaned_weights)\n",
    "\n",
    "    ret, volatility, sharpe_ratio = ef.portfolio_performance()\n",
    "    print(\"Expected annual return:\", ret)\n",
    "    print(\"Annual volatility:\", volatility)\n",
    "    print(\"Sharpe ratio:\", sharpe_ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dccb95",
   "metadata": {},
   "source": [
    "### Equity valuation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88957194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pypfopt import BlackLittermanModel, plotting\n",
    "from pypfopt import black_litterman, risk_models\n",
    "import datetime\n",
    "\n",
    "end_date = datetime.datetime.now()\n",
    "start_date = end_date - datetime.timedelta(days=5*365)\n",
    "apple_ticker = \"AAPL\"\n",
    "apple_data = yf.download(apple_ticker, start=start_date, end=end_date)\n",
    "microsoft_data = yf.download('MSFT', start=start_date, end=end_date)\n",
    "\n",
    "# # get dividends of the Apple stock\n",
    "# apple_stock = yf.Ticker(apple_ticker)\n",
    "# apple_dividends = apple_stock.dividends.loc[start_date:end_date]\n",
    "# apple_dividends = apple_dividends.reset_index(drop=True)\n",
    "\n",
    "# # get dividends of the Microsoft stock\n",
    "# microsoft_stock = yf.Ticker('MSFT')\n",
    "# microsoft_dividends = microsoft_stock.dividends.loc[start_date:end_date]\n",
    "# microsoft_dividends = microsoft_dividends.reset_index(drop=True)\n",
    "\n",
    "# Determine dividend for each stock\n",
    "dividends = {}\n",
    "for ticker in tickers:\n",
    "    stock = yf.Ticker(ticker)\n",
    "    dividends[ticker] = stock.dividends.loc[start_date:end_date]\n",
    "    dividends[ticker] = dividends[ticker].reset_index(drop=True)\n",
    "    dividends[ticker] = dividends[ticker] * 4\n",
    "print(dividends)\n",
    "\n",
    "# # Combine the dividend data into a single DataFrame (We are multiplying by 4 as these are quarterly dividends)\n",
    "# dividends = pd.DataFrame({'AAPL':apple_dividends*4, 'MSFT':microsoft_dividends*4})\n",
    "# #print(dividends)\n",
    "\n",
    "# Calculate the dividend growth rates\n",
    "dividends = pd.DataFrame(dividends)\n",
    "dividend_growth_rates = dividends.pct_change().dropna()\n",
    "\n",
    "# Since we only have dividend changes every 4 months, we remove the 0 values and get the average dividend growth rate which we consider as perpetual growth rate\n",
    "avg_dividends_growth_rate = dividend_growth_rates.mask(dividend_growth_rates == 0).sum()/5\n",
    "\n",
    "print(\"Dividend Growth rate: \\n\", avg_dividends_growth_rate)\n",
    "\n",
    "\n",
    "next_period_dividend = {}\n",
    "for ticker in tickers:\n",
    "    # Define the features and target variable for the machine learning model\n",
    "    X = np.unique(dividends[ticker].values)[:-1]  # Independent variables (dividend value for the past period)\n",
    "    y = np.unique(dividends[ticker].values)[1:]  # Dependent variable (dividend value for the next period)\n",
    "\n",
    "    # Train a machine learning model using regression to predict the next dividend value\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X.reshape(-1,1), y)\n",
    "\n",
    "    # Use the trained model to predict the dividend value for the next period\n",
    "    next_period_dividend[ticker] = model.predict(dividends[ticker].values[-1].reshape(1, -1))[0]\n",
    "    print(\"Predicted next period dividend\", next_period_dividend[ticker])\n",
    "\n",
    "\n",
    "# # PREDICTING NEXT DIVIDEND VALUE FOR APPLE STOCK\n",
    "\n",
    "# # Define the features and target variable for the machine learning model\n",
    "# X = np.unique(dividends['AAPL'].values)[:-1]  # Independent variables (dividend value for the past period)\n",
    "# y = np.unique(dividends['AAPL'].values)[1:]  # Dependent variable (dividend value for the next period)\n",
    "\n",
    "# # Train a machine learning model using regression to predict the next dividend value\n",
    "# model = RandomForestRegressor()\n",
    "# model.fit(X.reshape(-1,1), y)\n",
    "\n",
    "# # Use the trained model to predict the dividend value for the next period\n",
    "# next_period_dividend_apple = model.predict(dividends['AAPL'].values[-1].reshape(1, -1))[0]\n",
    "# print(\"Predicted next period dividend for APPLE\", next_period_dividend_apple)\n",
    "\n",
    "# # PREDICTING NEXT DIVIDEND VALUE FOR MICROSOFT STOCK\n",
    "\n",
    "# # Define the features and target variable for the machine learning model\n",
    "# X = np.unique(dividends['MSFT'].values)[:-1]  # Independent variables (dividend value for the past period)\n",
    "# y = np.unique(dividends['MSFT'].values)[1:]  # Dependent variable (dividend value for the next period)\n",
    "\n",
    "# # Train a machine learning model using regression to predict the next dividend value\n",
    "# model = RandomForestRegressor()\n",
    "# model.fit(X.reshape(-1,1), y)\n",
    "\n",
    "# # Use the trained model to predict the dividend value for the next period\n",
    "# next_period_dividend_microsoft = model.predict(dividends['MSFT'].values[-1].reshape(1, -1))[0]\n",
    "# print(\"Predicted next period dividend for Microsoft\", next_period_dividend_microsoft)\n",
    "\n",
    "# tickers = [\"AAPL\", \"AMZN\", \"BRK-B\", \"GOOGL\", \"META\", \"MSFT\", \"NVDA\", \"TSLA\", \"UNH\", \"XOM\"]\n",
    "\n",
    "\n",
    "discount_rate = {\n",
    "    \"AAPL\": 0.0871,\n",
    "    \"AMZN\": 0.0794,\n",
    "    \"BRK-B\": 0.0785,\n",
    "    \"GOOGL\": 0.0828,\n",
    "    \"META\": 0.0828,\n",
    "    \"MSFT\": 0.0871,\n",
    "    \"NVDA\": 0.0966,\n",
    "    \"TSLA\": 0.0942,\n",
    "    \"UNH\": 0.0832,\n",
    "    \"XOM\": 0.0875\n",
    "}\n",
    "\n",
    "intrinsic_prices = {}\n",
    "for ticker in tickers:\n",
    "    intrinsic_prices[ticker] = next_period_dividend[ticker] / \\\n",
    "                                    (discount_rate[ticker] - avg_dividends_growth_rate[ticker])\n",
    "print(intrinsic_prices)\n",
    "\n",
    "# # Apply the DDM formula to calculate the intrinsic value of the stocks\n",
    "# discount_rate = 0.078  # Available online\n",
    "# apple_intrinsic_price = next_period_dividend_apple / \\\n",
    "#     (discount_rate - avg_dividends_growth_rate['AAPL'])\n",
    "\n",
    "# discount_rate = 0.11\n",
    "# microsoft_intrinsic_price = next_period_dividend_microsoft / \\\n",
    "#     (discount_rate - avg_dividends_growth_rate['MSFT'])\n",
    "\n",
    "# print(\"Intrinsic Value of Apple Stock:\", apple_intrinsic_price)\n",
    "# print(\"Intrinsic Value of Microsoft Stock:\", microsoft_intrinsic_price)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# We can notice that the intrinsic stock values for both Apple and Microsoft are over-valued which makes sense as they are at their all-time high.\n",
    "\n",
    "# Use the intrinsic value of stock as views for BL model\n",
    "# Here We are filling our subjective views based on the fair price of the stocks that we calculated using Equity evaluation model\n",
    "viewdict = {}\n",
    "for key, value in portfolio_data.items():\n",
    "    viewdict[key] = intrinsic_prices[key]/value[-1]\n",
    "print(f\"Views: {viewdict}\")\n",
    "\n",
    "\n",
    "# viewdict = {'AAPL': apple_intrinsic_price/apple_data['Close'][-1], 'MSFT': microsoft_intrinsic_price/microsoft_data['Close'][-1]}\n",
    "# tickers = ['AAPL','MSFT']\n",
    "mcaps = {}\n",
    "for t in tickers:\n",
    "    stock = yf.Ticker(t)\n",
    "    mcaps[t] = stock.info[\"marketCap\"]\n",
    "# print(mcaps)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prices = portfolio_data\n",
    "# prices = pd.DataFrame({'AAPL':apple_data['Close'].values,'MSFT':microsoft_data['Close'].values})\n",
    "S = risk_models.CovarianceShrinkage(prices).ledoit_wolf()\n",
    "market_prices = yf.download(\"SPY\", period=\"max\")[\"Adj Close\"]\n",
    "\n",
    "\n",
    "delta = black_litterman.market_implied_risk_aversion(market_prices)\n",
    "# print(delta)\n",
    "market_prior = black_litterman.market_implied_prior_returns(mcaps, delta, S)\n",
    "# print(market_prior)\n",
    "\n",
    "# Assign confidence measure for stock returns based on some heuristics\n",
    "confidences = [\n",
    "    0.8,\n",
    "    0.6,\n",
    "    0.7,\n",
    "    0.5,\n",
    "    0.5,\n",
    "    0.7,\n",
    "    0.3,\n",
    "    0.3,\n",
    "    0.4,\n",
    "    0.7\n",
    "]\n",
    "\n",
    "# Fit BL model\n",
    "bl = BlackLittermanModel(S, pi=market_prior, absolute_views=viewdict, omega=\"idzorek\", view_confidences=confidences)\n",
    "\n",
    "# Get expected returns\n",
    "ret_bl = bl.bl_returns()\n",
    "# print(ret_bl)\n",
    "\n",
    "# Get cov matrix\n",
    "S_bl = bl.bl_cov()\n",
    "\n",
    "\n",
    "from pypfopt import EfficientFrontier, objective_functions\n",
    "\n",
    "ef = EfficientFrontier(ret_bl, S_bl)\n",
    "ef.add_objective(objective_functions.L2_reg)\n",
    "ef.max_sharpe()\n",
    "weights = ef.clean_weights()\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Final weights in the portfolio allocation: \")\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21598234",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, volatility, sharpe_ratio = ef.portfolio_performance()\n",
    "print(\"Expected annual return:\", ret)\n",
    "print(\"Annual volatility:\", volatility)\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea01344",
   "metadata": {},
   "source": [
    "### Black Litterman model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d86d1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "Non-linear ML model: RandomForestRegressor()\n",
      "Views: {'AAPL': 0.006209112706961326, 'AMZN': 0.00020208095672298753, 'BRK-B': -0.0020081740361084575, 'GOOGL': -0.0005828193338722599, 'META': 0.005138835875855064, 'MSFT': -0.0021289639883251468, 'NVDA': 0.007453707958223923, 'TSLA': -0.002047794054805434, 'UNH': 0.0017264527839735567, 'XOM': 0.0025365188668838336}\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "OrderedDict([('AAPL', 0.0), ('AMZN', 0.03228), ('BRK-B', 0.0), ('GOOGL', 0.00875), ('META', 0.06895), ('MSFT', 0.0), ('NVDA', 0.33891), ('TSLA', 0.55111), ('UNH', 0.0), ('XOM', 0.0)])\n",
      "Expected annual return: 0.05854902331028182\n",
      "Annual volatility: 0.5069027015794578\n",
      "Sharpe ratio: 0.07604817096094958\n",
      "----------------------------------------------------\n",
      "Non-linear ML model: GradientBoostingRegressor()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/efficient_frontier/efficient_frontier.py:259: UserWarning: max_sharpe transforms the optimization problem so additional objectives may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Views: {'AAPL': 0.006196333025294369, 'AMZN': -0.002198904307982675, 'BRK-B': 3.147106780534537e-05, 'GOOGL': 0.0017650839623249348, 'META': 0.006881351467200067, 'MSFT': -0.001199553848865692, 'NVDA': 0.005910369690964236, 'TSLA': 0.007813659522368505, 'UNH': 0.0031356609977219196, 'XOM': 0.001818884188573151}\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "OrderedDict([('AAPL', 0.0), ('AMZN', 0.01865), ('BRK-B', 0.0), ('GOOGL', 0.02079), ('META', 0.07633), ('MSFT', 0.0), ('NVDA', 0.3276), ('TSLA', 0.55663), ('UNH', 0.0), ('XOM', 0.0)])\n",
      "Expected annual return: 0.060073095579378843\n",
      "Annual volatility: 0.506791715237835\n",
      "Sharpe ratio: 0.07907212050728321\n",
      "----------------------------------------------------\n",
      "Non-linear ML model: MLPRegressor(hidden_layer_sizes=(100, 100))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/efficient_frontier/efficient_frontier.py:259: UserWarning: max_sharpe transforms the optimization problem so additional objectives may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Views: {'AAPL': 0.00629254997744275, 'AMZN': -0.002507485707500907, 'BRK-B': -0.0012916000309219466, 'GOOGL': -0.001520742433792084, 'META': 0.008123913109443713, 'MSFT': -0.0006810750047136926, 'NVDA': 0.004440850635622371, 'TSLA': -0.0011307364644292971, 'UNH': 0.002140110500490017, 'XOM': -9.640036431973309e-05}\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "OrderedDict([('AAPL', 0.0), ('AMZN', 0.01833), ('BRK-B', 0.0), ('GOOGL', 0.00741), ('META', 0.08413), ('MSFT', 0.0), ('NVDA', 0.33585), ('TSLA', 0.55428), ('UNH', 0.0), ('XOM', 0.0)])\n",
      "Expected annual return: 0.05856272031556069\n",
      "Annual volatility: 0.5079242328024777\n",
      "Sharpe ratio: 0.07592219040779062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/efficient_frontier/efficient_frontier.py:259: UserWarning: max_sharpe transforms the optimization problem so additional objectives may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reg_models = [RandomForestRegressor(), GradientBoostingRegressor(), MLPRegressor(hidden_layer_sizes=(100, 100))]\n",
    "\n",
    "for reg_model in reg_models:\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(f\"Non-linear ML model: {reg_model}\")\n",
    "    \n",
    "    # Using a non-linear ML model to predict stock prices in future\n",
    "    returns = {}\n",
    "    future_returns = {}\n",
    "    for ticker in tickers:\n",
    "        stock_returns = ((portfolio_data[ticker] / portfolio_data[ticker].shift(1))-1).dropna().tolist()\n",
    "        returns[ticker] = stock_returns\n",
    "\n",
    "        stock_x = [stock_returns[i:i+10] for i in range(len(stock_returns)-20)]\n",
    "        stock_y = [stock_returns[i+10] for i in range(10,len(stock_returns)-10)]\n",
    "        stock_test = [stock_returns[i:i+10] for i in range(len(stock_returns)-20,len(stock_returns)-10)]\n",
    "        reg = RandomForestRegressor()\n",
    "        reg.fit(stock_x,stock_y)\n",
    "        future_returns[ticker] = reg.predict(stock_test)\n",
    "\n",
    "    # Using the predicted future return of stocks as \"views\" for black litterman model\n",
    "    viewdict = {key: value[-1] for key, value in future_returns.items()}\n",
    "    print(f\"Views: {viewdict}\")\n",
    "\n",
    "    # Obtain market caps for all stocks in portfolio\n",
    "    mcaps = {}\n",
    "    for t in tickers:\n",
    "        stock = yf.Ticker(t)\n",
    "        mcaps[t] = stock.info[\"marketCap\"]\n",
    "\n",
    "    # Determine prior estimate of returns implied by the market weights\n",
    "    S = risk_models.CovarianceShrinkage(portfolio_data).ledoit_wolf()\n",
    "    market_prices = yf.download(\"SPY\", period=\"max\")[\"Adj Close\"]\n",
    "    delta = black_litterman.market_implied_risk_aversion(market_prices)\n",
    "    market_prior = black_litterman.market_implied_prior_returns(mcaps, delta, S)\n",
    "\n",
    "    # Assign confidence measure for stock returns based on some heuristics\n",
    "    confidences = [\n",
    "        0.8,\n",
    "        0.6,\n",
    "        0.7,\n",
    "        0.5,\n",
    "        0.5,\n",
    "        0.7,\n",
    "        0.3,\n",
    "        0.3,\n",
    "        0.4,\n",
    "        0.7\n",
    "    ]\n",
    "\n",
    "    # Fit the Black litterman model and calculate corresponding cov matrix and returns\n",
    "    bl = BlackLittermanModel(S, pi=market_prior, absolute_views=viewdict, omega=\"idzorek\", view_confidences=confidences)\n",
    "    ret_bl = bl.bl_returns()\n",
    "    S_bl = bl.bl_cov()\n",
    "\n",
    "    # Find the optimal weights using bl cov matrix and returns\n",
    "    ef = EfficientFrontier(ret_bl, S_bl)\n",
    "    ef.add_objective(objective_functions.L2_reg)\n",
    "    ef.max_sharpe()\n",
    "    weights = ef.clean_weights()\n",
    "    print(weights)\n",
    "\n",
    "    ret, volatility, sharpe_ratio = ef.portfolio_performance()\n",
    "    print(\"Expected annual return:\", ret)\n",
    "    print(\"Annual volatility:\", volatility)\n",
    "    print(\"Sharpe ratio:\", sharpe_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d2853f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
