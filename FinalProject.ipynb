{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c3d512f",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576833bf",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3698336",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using the following machine learning models for making predictions for the following portfolio optimization models:\n",
    "- Mean-variance optimization (chapter 7 of Bodie, Investment book)\n",
    "- Index model (chapter 8 of Bodie, Investment book)\n",
    "- Capital asset pricing model (chapter 9 of Bodie, Investment book)\n",
    "- Arbitrage pricing theory and multifactor model (chapter 10 of Bodie,\n",
    "Investment book)\n",
    "- Equity valuation model (chapter 18 of Bodie, Investment book)\n",
    "- Black Litterman model (chapter 24 of Bodie, Investment book)\n",
    "- Algorithmic trading (this could be restricted to the last month)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5455474e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40e998cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  10 of 10 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>BRK-B</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>META</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>UNH</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-06-26</th>\n",
       "      <td>185.270004</td>\n",
       "      <td>127.330002</td>\n",
       "      <td>334.119995</td>\n",
       "      <td>118.339996</td>\n",
       "      <td>278.470001</td>\n",
       "      <td>328.600006</td>\n",
       "      <td>406.320007</td>\n",
       "      <td>241.050003</td>\n",
       "      <td>479.059998</td>\n",
       "      <td>104.290001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-27</th>\n",
       "      <td>188.059998</td>\n",
       "      <td>129.179993</td>\n",
       "      <td>335.339996</td>\n",
       "      <td>118.330002</td>\n",
       "      <td>287.049988</td>\n",
       "      <td>334.570007</td>\n",
       "      <td>418.760010</td>\n",
       "      <td>250.210007</td>\n",
       "      <td>482.559998</td>\n",
       "      <td>104.550003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28</th>\n",
       "      <td>189.250000</td>\n",
       "      <td>129.039993</td>\n",
       "      <td>334.149994</td>\n",
       "      <td>120.180000</td>\n",
       "      <td>285.290009</td>\n",
       "      <td>335.850006</td>\n",
       "      <td>411.170013</td>\n",
       "      <td>256.239990</td>\n",
       "      <td>474.450012</td>\n",
       "      <td>105.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29</th>\n",
       "      <td>189.589996</td>\n",
       "      <td>127.900002</td>\n",
       "      <td>336.910004</td>\n",
       "      <td>119.099998</td>\n",
       "      <td>281.529999</td>\n",
       "      <td>335.049988</td>\n",
       "      <td>408.220001</td>\n",
       "      <td>257.500000</td>\n",
       "      <td>476.440002</td>\n",
       "      <td>106.699997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>193.970001</td>\n",
       "      <td>130.360001</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>119.699997</td>\n",
       "      <td>286.980011</td>\n",
       "      <td>340.540009</td>\n",
       "      <td>423.019989</td>\n",
       "      <td>261.769989</td>\n",
       "      <td>480.640015</td>\n",
       "      <td>107.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AAPL        AMZN       BRK-B       GOOGL        META  \\\n",
       "Date                                                                     \n",
       "2023-06-26  185.270004  127.330002  334.119995  118.339996  278.470001   \n",
       "2023-06-27  188.059998  129.179993  335.339996  118.330002  287.049988   \n",
       "2023-06-28  189.250000  129.039993  334.149994  120.180000  285.290009   \n",
       "2023-06-29  189.589996  127.900002  336.910004  119.099998  281.529999   \n",
       "2023-06-30  193.970001  130.360001  341.000000  119.699997  286.980011   \n",
       "\n",
       "                  MSFT        NVDA        TSLA         UNH         XOM  \n",
       "Date                                                                    \n",
       "2023-06-26  328.600006  406.320007  241.050003  479.059998  104.290001  \n",
       "2023-06-27  334.570007  418.760010  250.210007  482.559998  104.550003  \n",
       "2023-06-28  335.850006  411.170013  256.239990  474.450012  105.400002  \n",
       "2023-06-29  335.049988  408.220001  257.500000  476.440002  106.699997  \n",
       "2023-06-30  340.540009  423.019989  261.769989  480.640015  107.250000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "from pypfopt import plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pypfopt import expected_returns, risk_models, EfficientFrontier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "tickers = [\"AAPL\", \"AMZN\", \"BRK-B\", \"GOOGL\", \"META\", \"MSFT\", \"NVDA\", \"TSLA\", \"UNH\", \"XOM\"]\n",
    "portfolio_data = yf.download(tickers, period=\"5y\")\n",
    "portfolio_data = portfolio_data[\"Adj Close\"]\n",
    "portfolio_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "937b3971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2023-06-26    4328.819824\n",
       "2023-06-27    4378.410156\n",
       "2023-06-28    4376.859863\n",
       "2023-06-29    4396.439941\n",
       "2023-06-30    4450.379883\n",
       "Name: Adj Close, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_index_ticker = \"^GSPC\"  # S&P 500 index\n",
    "market_index_data = yf.download(market_index_ticker, period=\"5y\")\n",
    "market_index_data = market_index_data[\"Adj Close\"]\n",
    "market_index_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c777d4",
   "metadata": {},
   "source": [
    "## Mean Variance Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0515cab1",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88edd1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_prices = {}\n",
    "for ticker in tickers:\n",
    "    data = portfolio_data[ticker].tolist()\n",
    "    # Dependent variable - 10 consecutive days of stock prices\n",
    "    dev_x = [data[i:i+10] for i in range(len(data)-20)]\n",
    "    \n",
    "    # Independent variable - stock price 10th day into the future\n",
    "    dev_y = [data[i+10] for i in range(10,len(data)-10)]\n",
    "    \n",
    "    test = [data[i:i+10] for i in range(len(data)-20,len(data)-10)]\n",
    "    \n",
    "    reg = RandomForestRegressor()\n",
    "    reg.fit(dev_x,dev_y)\n",
    "    \n",
    "    # Predict stock price for 10 future days\n",
    "    pred = reg.predict(test)\n",
    "    future_prices[ticker] = pred\n",
    "\n",
    "future_prices = pd.DataFrame(future_prices)\n",
    "# Construct covariance matrix of future stock prices\n",
    "S = risk_models.CovarianceShrinkage(future_prices).ledoit_wolf()\n",
    "\n",
    "# Use capm to find expected returns on future prices\n",
    "mu = expected_returns.capm_return(future_prices)\n",
    "print(mu)\n",
    "\n",
    "# Do mean variance optimization using efficient frontier\n",
    "ef = EfficientFrontier(mu, S)\n",
    "ef.min_volatility()\n",
    "weights = ef.clean_weights()\n",
    "print(weights)\n",
    "# weights = ef.max_sharpe(risk_free_rate=0.02)\n",
    "# cleaned_weights = ef.clean_weights()\n",
    "# print(cleaned_weights)\n",
    "\n",
    "ret, volatility, sharpe_ratio = ef.portfolio_performance()\n",
    "print(\"Expected annual return:\", ret)\n",
    "print(\"Annual volatility:\", volatility)\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd90b9",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13084abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_prices = {}\n",
    "for ticker in tickers:\n",
    "    data = portfolio_data[ticker].tolist()\n",
    "    dev_x = [data[i:i+10] for i in range(len(data)-20)]\n",
    "    dev_y = [data[i+10] for i in range(10, len(data)-10)]\n",
    "    test = [data[i:i+10] for i in range(len(data)-20, len(data)-10)]\n",
    "    \n",
    "    reg = SVR()\n",
    "    reg.fit(dev_x, dev_y)\n",
    "    \n",
    "    pred = reg.predict(test)\n",
    "    future_prices[ticker] = pred\n",
    "\n",
    "future_prices = pd.DataFrame(future_prices)\n",
    "\n",
    "S = risk_models.CovarianceShrinkage(future_prices).ledoit_wolf()\n",
    "mu = expected_returns.capm_return(future_prices)\n",
    "print(mu)\n",
    "\n",
    "ef = EfficientFrontier(mu, S)\n",
    "ef.min_volatility()\n",
    "weights = ef.clean_weights()\n",
    "print(weights)\n",
    "\n",
    "\n",
    "ret, volatility, sharpe_ratio = ef.portfolio_performance()\n",
    "print(\"Expected annual return:\", ret)\n",
    "print(\"Annual volatility:\", volatility)\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894acc7c",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbad704",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_prices = {}\n",
    "for ticker in tickers:\n",
    "    data = portfolio_data[ticker].tolist()\n",
    "    dev_x = [data[i:i+10] for i in range(len(data)-20)]\n",
    "    dev_y = [data[i+10] for i in range(10, len(data)-10)]\n",
    "    test = [data[i:i+10] for i in range(len(data)-20, len(data)-10)]\n",
    "    \n",
    "    reg = MLPRegressor(hidden_layer_sizes=(100,100), random_state=42)  # You can adjust the hidden_layer_sizes and other parameters as needed\n",
    "    reg.fit(dev_x, dev_y)\n",
    "    \n",
    "    pred = reg.predict(test)\n",
    "    future_prices[ticker] = pred\n",
    "\n",
    "future_prices = pd.DataFrame(future_prices)\n",
    "\n",
    "S = risk_models.CovarianceShrinkage(future_prices).ledoit_wolf()\n",
    "mu = expected_returns.capm_return(future_prices)\n",
    "print(mu)\n",
    "\n",
    "ef = EfficientFrontier(mu, S)\n",
    "ef.min_volatility()\n",
    "weights = ef.clean_weights()\n",
    "print(weights)\n",
    "\n",
    "ret, volatility, sharpe_ratio = ef.portfolio_performance()\n",
    "print(\"Expected annual return:\", ret)\n",
    "print(\"Annual volatility:\", volatility)\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e43441",
   "metadata": {},
   "source": [
    "## Index model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleIndexModel:\n",
    "    def __init__(self, tickers, market_index_data, portfolio_data, reg_model):\n",
    "        self.tickers = tickers\n",
    "        self.market_index_data = market_index_data\n",
    "        self.portfolio_data = portfolio_data\n",
    "        self.reg_model = reg_model\n",
    "        self.returns = {}\n",
    "        self.beta = {}\n",
    "        self.alpha = {}\n",
    "        self.residual_variance = {}\n",
    "\n",
    "    def calculate_returns(self):\n",
    "        # Returns of stocks and market\n",
    "        self.returns = {\"MARKET\": ((self.market_index_data / self.market_index_data.shift(1)) - 1).dropna().tolist()}\n",
    "        for ticker in self.tickers:\n",
    "            self.returns[ticker] = ((self.portfolio_data[ticker] / self.portfolio_data[ticker].shift(1))-1).dropna().tolist()\n",
    "\n",
    "    def fit_regression(self):\n",
    "        # Forecast market\n",
    "        market_x = [self.returns[\"MARKET\"][i:i+10] for i in range(len(self.returns[\"MARKET\"])-20)]\n",
    "        market_y = [self.returns[\"MARKET\"][i+10] for i in range(10, len(self.returns[\"MARKET\"])-10)]\n",
    "        market_test = [self.returns[\"MARKET\"][i:i+10] \n",
    "                       for i in range(len(self.returns[\"MARKET\"])-20, len(self.returns[\"MARKET\"])-10)]\n",
    "\n",
    "        reg = self.reg_model\n",
    "        reg.fit(market_x, market_y)\n",
    "        market_future = reg.predict(market_test)\n",
    "\n",
    "        # Forecast each stock\n",
    "        for ticker in self.tickers:\n",
    "            stock_x = [self.returns[ticker][i:i+10] for i in range(len(self.returns[ticker])-20)]\n",
    "            stock_y = [self.returns[ticker][i+10] for i in range(10, len(self.returns[ticker])-10)]\n",
    "            stock_test = [self.returns[ticker][i:i+10]\n",
    "                          for i in range(len(self.returns[ticker])-20, len(self.returns[ticker])-10)]\n",
    "\n",
    "            reg = self.reg_model\n",
    "            reg.fit(stock_x, stock_y)\n",
    "            stock_future = reg.predict(stock_test)\n",
    "\n",
    "            single_index_reg = LinearRegression()\n",
    "            single_index_reg.fit(np.array(market_future).reshape(-1, 1), y=stock_future)\n",
    "\n",
    "            self.beta[ticker] = single_index_reg.coef_[0]\n",
    "            self.alpha[ticker] = single_index_reg.intercept_\n",
    "\n",
    "            y_pred = single_index_reg.predict(np.array(self.returns[\"MARKET\"]).reshape(-1, 1))\n",
    "            residuals = self.returns[ticker] - y_pred\n",
    "            self.residual_variance[ticker] = np.var(residuals)\n",
    "\n",
    "    def optimize_portfolio(self):\n",
    "        # Compute the initial position of each security\n",
    "        weights = {ticker: self.alpha[ticker] / self.residual_variance[ticker] for ticker in self.tickers}\n",
    "        total_weight = sum(weights.values())\n",
    "        weights = {ticker: weight / total_weight for ticker, weight in weights.items()}\n",
    "\n",
    "        # Compute the alpha of the active portfolio\n",
    "        alpha_portfolio = sum(weights[ticker] * self.alpha[ticker] for ticker in self.tickers)\n",
    "\n",
    "        # Compute the residual variance of the active portfolio\n",
    "        residual_variance_portfolio = sum((weights[ticker] ** 2) * self.residual_variance[ticker] for ticker in self.tickers)\n",
    "\n",
    "        # Compute the initial position in the active portfolio\n",
    "        residual_variance_market = 0.0114  # Variance of S&P 500\n",
    "        risk_premium_market = 0.056\n",
    "        initial_position_portfolio = (alpha_portfolio * residual_variance_market) / (residual_variance_portfolio * risk_premium_market)\n",
    "\n",
    "        # Compute the beta of the active portfolio\n",
    "        beta_portfolio = sum(weights[ticker] * self.beta[ticker] for ticker in self.tickers)\n",
    "\n",
    "        # Adjust the initial position in the active portfolio\n",
    "        adjusted_position_portfolio = initial_position_portfolio / (1 + (1 - beta_portfolio) * initial_position_portfolio)\n",
    "\n",
    "        # Optimal risky portfolio now has weights\n",
    "        final_weight_market = 1 - adjusted_position_portfolio\n",
    "        weights = {ticker: weight * adjusted_position_portfolio for ticker, weight in weights.items()}\n",
    "\n",
    "        # Calculate the risk premium of the portfolio\n",
    "        risk_premium_portfolio = (final_weight_market + adjusted_position_portfolio * beta_portfolio) * risk_premium_market + adjusted_position_portfolio * alpha_portfolio\n",
    "\n",
    "        # Compute the variance of the portfolio\n",
    "        portfolio_variance = (final_weight_market + adjusted_position_portfolio * beta_portfolio) ** 2 * residual_variance_market + adjusted_position_portfolio ** 2 * residual_variance_portfolio\n",
    "\n",
    "        # Calculate the Sharpe ratio\n",
    "        sharpe_ratio = risk_premium_portfolio / (portfolio_variance ** 0.5)\n",
    "\n",
    "        return weights, final_weight_market, sharpe_ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdc52d5",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c642ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = RandomForestRegressor()\n",
    "portfolio = SingleIndexModel(tickers, market_index_data, portfolio_data, reg_model)\n",
    "portfolio.calculate_returns()\n",
    "portfolio.fit_regression()\n",
    "weights, final_weight_market, sharpe_ratio = portfolio.optimize_portfolio()\n",
    "print(\"------------------------------\")\n",
    "print(\"Final Weights:\")\n",
    "print(\"Weight Market S&P:\", final_weight_market)\n",
    "print(f\"Weights: {weights}\")\n",
    "print(\"------------------------------\")\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa76324",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b45800",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = SVR()\n",
    "portfolio = SingleIndexModel(tickers, market_index_data, portfolio_data, reg_model)\n",
    "portfolio.calculate_returns()\n",
    "portfolio.fit_regression()\n",
    "weights, final_weight_market, sharpe_ratio = portfolio.optimize_portfolio()\n",
    "print(\"------------------------------\")\n",
    "print(\"Final Weights:\")\n",
    "print(\"Weight Market S&P:\", final_weight_market)\n",
    "print(f\"Weights: {weights}\")\n",
    "print(\"------------------------------\")\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8fade6",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e57a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = MLPRegressor(hidden_layer_sizes=(100,100))\n",
    "portfolio = SingleIndexModel(tickers, market_index_data, portfolio_data, reg_model)\n",
    "portfolio.calculate_returns()\n",
    "portfolio.fit_regression()\n",
    "weights, final_weight_market, sharpe_ratio = portfolio.optimize_portfolio()\n",
    "print(\"------------------------------\")\n",
    "print(\"Final Weights:\")\n",
    "print(\"Weight Market S&P:\", final_weight_market)\n",
    "print(f\"Weights: {weights}\")\n",
    "print(\"------------------------------\")\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db4f9d8",
   "metadata": {},
   "source": [
    "### Capital asset pricing model (CAPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b915a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = {\"MARKET\": ((market_index_data / market_index_data.shift(1)) - 1).dropna().tolist()}\n",
    "for ticker in tickers:\n",
    "    returns[ticker] = ((portfolio_data[ticker] / portfolio_data[ticker].shift(1))-1).dropna().tolist()\n",
    "\n",
    "print(returns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482e4ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_x = [returns[\"MARKET\"][i:i+10] for i in range(len(returns[\"MARKET\"])-20)]\n",
    "market_y = [returns[\"MARKET\"][i+10] for i in range(10, len(returns[\"MARKET\"])-10)]\n",
    "market_test = [returns[\"MARKET\"][i:i+10]\n",
    "               for i in range(len(returns[\"MARKET\"])-20, len(returns[\"MARKET\"])-10)]\n",
    "\n",
    "reg = MLPRegressor(hidden_layer_sizes=(100,100))\n",
    "reg.fit(market_x, market_y)\n",
    "market_future = reg.predict(market_test)\n",
    "print(market_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca74a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_returns = {}\n",
    "for ticker in tickers:\n",
    "    single_index_reg = Ridge()\n",
    "    single_index_reg.fit(np.array(returns[\"MARKET\"]).reshape(-1, 1), y=returns[ticker])\n",
    "    future_returns[ticker] = single_index_reg.predict(np.array(market_future).reshape(-1, 1))\n",
    "\n",
    "future_returns = pd.DataFrame(future_returns)\n",
    "print(future_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94933acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = risk_models.sample_cov(future_returns)\n",
    "S = risk_models.CovarianceShrinkage(future_returns).ledoit_wolf()\n",
    "plotting.plot_covariance(S, plot_correlation=True)\n",
    "# You don't have to provide expected returns in this case\n",
    "\n",
    "\n",
    "ef = EfficientFrontier(None, S)\n",
    "ef.min_volatility()\n",
    "weights = ef.clean_weights()\n",
    "print(weights)\n",
    "# weights = ef.max_sharpe(risk_free_rate=-0.2)\n",
    "# cleaned_weights = ef.clean_weights()\n",
    "# print(cleaned_weights)\n",
    "# print(mu)\n",
    "\n",
    "ret, volatility, sharpe_ratio = ef.portfolio_performance()\n",
    "print(\"Expected annual return:\", ret)\n",
    "print(\"Annual volatility:\", volatility)\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e78f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt import expected_returns\n",
    "from pypfopt import plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from pypfopt import expected_returns, risk_models, EfficientFrontier\n",
    "\n",
    "# T-bill rate\n",
    "risk_free_rate = 0.01\n",
    "\n",
    "# apple_returns = (\n",
    "#     (portfolio_data[\"AAPL\"] / portfolio_data[\"AAPL\"].shift(1))-1-risk_free_rate).dropna().tolist()\n",
    "# google_returns = (\n",
    "#     (portfolio_data[\"GOOGL\"] / portfolio_data[\"GOOGL\"].shift(1))-1-risk_free_rate).dropna().tolist()\n",
    "# market_returns = (\n",
    "#     (market_index_data / market_index_data.shift(1))-1-risk_free_rate).dropna().tolist()\n",
    "\n",
    "# returns = {\"MARKET\": ((market_index_data / market_index_data.shift(1)) - 1).dropna().tolist()}\n",
    "# for ticker in self.tickers:\n",
    "#     returns[ticker] = ((portfolio_data[ticker] / portfolio_data[ticker].shift(1))-1).dropna().tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# apple_prices = apple_data['Close'].tolist()\n",
    "# google_prices = google_data['Close'].tolist()\n",
    "market_x = [returns[\"MARKET\"][i:i+10] for i in range(len(returns[\"MARKET\"])-20)]\n",
    "market_y = [returns[\"MARKET\"][i+10] for i in range(10, len(returns[\"MARKET\"])-10)]\n",
    "market_test = [returns[\"MARKET\"][i:i+10]\n",
    "               for i in range(len(returns[\"MARKET\"])-20, len(returns[\"MARKET\"])-10)]\n",
    "\n",
    "# reg = MLPRegressor(hidden_layer_sizes=(100,100))\n",
    "# reg = SVR()\n",
    "reg = RandomForestRegressor()\n",
    "\n",
    "reg.fit(market_x, market_y)\n",
    "market_future = reg.predict(market_test)\n",
    "\n",
    "# print(market_future)\n",
    "\n",
    "single_index_reg = Ridge()\n",
    "single_index_reg.fit(np.array(market_returns).reshape(-1, 1), y=apple_returns)\n",
    "apple_future = single_index_reg.predict(np.array(market_future).reshape(-1, 1))\n",
    "\n",
    "single_index_reg = Ridge()\n",
    "single_index_reg.fit(np.array(market_returns).reshape(-1, 1), google_returns)\n",
    "google_future = single_index_reg.predict(\n",
    "    np.array(market_future).reshape(-1, 1))\n",
    "\n",
    "future_returns = {'apple': apple_future, 'google': google_future}\n",
    "future_returns = pd.DataFrame(future_returns)\n",
    "\n",
    "print(future_returns)\n",
    "\n",
    "S = risk_models.sample_cov(future_returns)\n",
    "# S = risk_models.CovarianceShrinkage(future_returns).ledoit_wolf()\n",
    "# plotting.plot_covariance(S, plot_correlation=True)\n",
    "# You don't have to provide expected returns in this case\n",
    "\n",
    "\n",
    "ef = EfficientFrontier(None, S)\n",
    "ef.min_volatility()\n",
    "weights = ef.clean_weights()\n",
    "print(weights)\n",
    "# weights = ef.max_sharpe(risk_free_rate=-0.2)\n",
    "# cleaned_weights = ef.clean_weights()\n",
    "# print(cleaned_weights)\n",
    "# print(mu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a626fe31",
   "metadata": {},
   "source": [
    "### Arbitrage pricing theory and multifactor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "412cf40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n",
      "{2018: -0.8731875620129659, 2019: -0.23617811356352036, 2020: -1.5469812407578423, 2021: 0.43936719519542417, 2022: 0.8457453584592317, 2023: 1.3712343626796726}\n",
      "Coefficients:  [ 0.23246483 -0.03089709 -0.00044608]\n",
      "Coefficients:  [ 0.21129307 -0.0063862  -0.00060686]\n",
      "Coefficients:  [ 1.58778199e-01 -4.07203433e-02  8.75369524e-05]\n",
      "Coefficients:  [ 2.14849351e-01 -2.47570555e-02 -1.17051810e-04]\n",
      "Coefficients:  [ 0.24144847 -0.01881288  0.0003029 ]\n",
      "Coefficients:  [ 0.22608141 -0.02379256 -0.00022933]\n",
      "Coefficients:  [ 0.32829186 -0.02308871  0.00043708]\n",
      "Coefficients:  [ 0.27754668 -0.02512154 -0.0027244 ]\n",
      "Coefficients:  [ 0.16541739 -0.03677604 -0.00030013]\n",
      "Coefficients:  [ 0.16781951 -0.07024288  0.00121478]\n",
      "       AAPL      AMZN     BRK-B     GOOGL      META      MSFT      NVDA  \\\n",
      "0  0.000979 -0.000097  0.000887  0.000828  0.001351  0.001096  0.003034   \n",
      "1  0.000625 -0.000397  0.000626  0.000505  0.000996  0.000758  0.002554   \n",
      "2  0.000813 -0.000211  0.000741  0.000681  0.001200  0.000945  0.002834   \n",
      "3  0.000969 -0.000089  0.000865  0.000821  0.001350  0.001091  0.003035   \n",
      "4  0.000779 -0.000241  0.000716  0.000649  0.001166  0.000912  0.002787   \n",
      "5  0.001026 -0.000038  0.000904  0.000874  0.001409  0.001146  0.003116   \n",
      "6  0.000654 -0.000356  0.000632  0.000534  0.001035  0.000790  0.002609   \n",
      "7  0.001102  0.000041  0.000947  0.000946  0.001494  0.001223  0.003232   \n",
      "8  0.000486 -0.000507  0.000516  0.000379  0.000861  0.000627  0.002373   \n",
      "9  0.000751 -0.000250  0.000683  0.000627  0.001147  0.000890  0.002763   \n",
      "\n",
      "       TSLA       UNH       XOM  \n",
      "0 -0.000794  0.000521  0.002624  \n",
      "1 -0.001205  0.000255  0.002323  \n",
      "2 -0.000972  0.000378  0.002424  \n",
      "3 -0.000797  0.000502  0.002580  \n",
      "4 -0.001012  0.000353  0.002397  \n",
      "5 -0.000729  0.000543  0.002622  \n",
      "6 -0.001163  0.000265  0.002311  \n",
      "7 -0.000633  0.000591  0.002656  \n",
      "8 -0.001362  0.000144  0.002185  \n",
      "9 -0.001037  0.000322  0.002342  \n",
      "            AAPL         AMZN      BRK-B      GOOGL       META       MSFT  \\\n",
      "AAPL   49.501029    52.635942  37.077343  55.195832  33.914902  40.771216   \n",
      "AMZN   52.635942  8428.209942  42.470860  54.882134  46.837709  50.107393   \n",
      "BRK-B  37.077343    42.470860  28.054903  41.210515  25.479807  30.597566   \n",
      "GOOGL  55.195832    54.882134  41.210515  61.611345  37.769375  45.426551   \n",
      "META   33.914902    46.837709  25.479807  37.769375  23.298101  27.976608   \n",
      "MSFT   40.771216    50.107393  30.597566  45.426551  27.976608  33.610858   \n",
      "NVDA   19.389574    32.776639  14.626995  21.561036  13.353070  16.017972   \n",
      "TSLA  -56.578684  -215.742321 -43.215289 -62.611040 -39.366898 -47.012532   \n",
      "UNH    82.977068    50.331138  61.483783  92.901736  56.465744  68.067291   \n",
      "XOM    12.526086    17.050639   9.590525  13.868584   8.646347  10.365409   \n",
      "\n",
      "            NVDA        TSLA         UNH        XOM  \n",
      "AAPL   19.389574  -56.578684   82.977068  12.526086  \n",
      "AMZN   32.776639 -215.742321   50.331138  17.050639  \n",
      "BRK-B  14.626995  -43.215289   61.483783   9.590525  \n",
      "GOOGL  21.561036  -62.611040   92.901736  13.868584  \n",
      "META   13.353070  -39.366898   56.465744   8.646347  \n",
      "MSFT   16.017972  -47.012532   68.067291  10.365409  \n",
      "NVDA    7.673561  -22.867259   32.069225   4.991043  \n",
      "TSLA  -22.867259   71.697102  -91.489105 -15.021750  \n",
      "UNH    32.069225  -91.489105  141.918390  20.480157  \n",
      "XOM     4.991043  -15.021750   20.480157   3.326186  \n",
      "AAPL     0.000819\n",
      "AMZN    -0.000215\n",
      "BRK-B    0.000752\n",
      "GOOGL    0.000684\n",
      "META     0.001201\n",
      "MSFT     0.000948\n",
      "NVDA     0.002834\n",
      "TSLA    -0.000970\n",
      "UNH      0.000387\n",
      "XOM      0.002446\n",
      "dtype: float64\n",
      "OrderedDict([('AAPL', 0.0), ('AMZN', 0.00301), ('BRK-B', 0.0), ('GOOGL', 0.0), ('META', 0.0), ('MSFT', 0.0), ('NVDA', 0.09052), ('TSLA', 0.18807), ('UNH', 0.0), ('XOM', 0.7184)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/risk_models.py:70: UserWarning: The covariance matrix is non positive semidefinite. Amending eigenvalues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from pypfopt import expected_returns\n",
    "# from pypfopt import plotting\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "# Example tickers for S&P 500, and 20+ Year Treasury Bond ETFs\n",
    "factor_tickers = ['SPY', 'TLT']\n",
    "\n",
    "# Fetch historical data for the macroeconomic factors S&P and Treasury Bond\n",
    "factor_data = yf.download(factor_tickers, period=\"5y\")\n",
    "\n",
    "factor_data = factor_data['Adj Close']\n",
    "\n",
    "# Calculate the returns for the S&P and Treasury bond factors\n",
    "factor_returns = factor_data.pct_change().dropna()\n",
    "spy_returns = factor_returns['SPY']\n",
    "tlt_returns = factor_returns['TLT']\n",
    "\n",
    "# FACTOR 1\n",
    "# Train ML model to predict future price of S&P market factors\n",
    "spy_x = [spy_returns[i:i+10] for i in range(len(spy_returns)-20)]\n",
    "spy_y = [spy_returns[i+10] for i in range(10, len(spy_returns)-10)]\n",
    "\n",
    "spy_test = [spy_returns[i:i+10]\n",
    "               for i in range(len(spy_returns)-20, len(spy_returns)-10)]\n",
    "reg = MLPRegressor(hidden_layer_sizes=(100, 100))\n",
    "reg.fit(spy_x, spy_y)\n",
    "spy_future = reg.predict(spy_test)\n",
    "\n",
    "# FACTOR 2\n",
    "# Train ML model to predict future price of Treasury Bond ETF factors\n",
    "tlt_x = [tlt_returns[i:i+10] for i in range(len(tlt_returns)-20)]\n",
    "tlt_y = [tlt_returns[i+10] for i in range(10, len(tlt_returns)-10)]\n",
    "\n",
    "tlt_test = [tlt_returns[i:i+10]\n",
    "               for i in range(len(tlt_returns)-20, len(tlt_returns)-10)]\n",
    "\n",
    "reg = MLPRegressor(hidden_layer_sizes=(100, 100))\n",
    "reg.fit(tlt_x, tlt_y)\n",
    "tlt_future = reg.predict(tlt_test)\n",
    "\n",
    "# FACTOR 3\n",
    "# GDP Price of USA for past 5 years\n",
    "\n",
    "# US GDP per capita Prices of last 5 years\n",
    "GDP_prices = {\n",
    "        2018: 59607,\n",
    "        2019: 60698,\n",
    "        2020: 58453,\n",
    "        2021: 61855,\n",
    "        2022: 62551,\n",
    "        2023: 63451 # Forecast data also available online\n",
    "    }\n",
    "\n",
    "# Normalize the GDP values as it will make the other factors irrelevant as it is very large\n",
    "values = list(GDP_prices.values())\n",
    "values_array = [[value] for value in values]\n",
    "scaler = StandardScaler()\n",
    "scaled_values = scaler.fit_transform(values_array)\n",
    "scaled_values = scaled_values.flatten()\n",
    "scaled_GDP_prices = {year: scaled_value for year, scaled_value in zip(GDP_prices.keys(), scaled_values)}\n",
    "\n",
    "print(scaled_GDP_prices)\n",
    "\n",
    "for index, row in factor_returns.iterrows():\n",
    "    # Extract the year from the date\n",
    "    year = index.year\n",
    "\n",
    "    # Fill the 'GDP' column with the corresponding GDP price based on the year\n",
    "    factor_returns.at[index, 'GDP'] = scaled_GDP_prices.get(year)\n",
    "\n",
    "future_factors = {'SPY': spy_future, 'TLT': tlt_future, 'GDP': [scaled_GDP_prices.get(2023)]*10}\n",
    "future_factors = pd.DataFrame(future_factors)\n",
    "#print(future_factors)\n",
    "\n",
    "# ð‘Ÿ=ð¸(ð‘Ÿ)+ð›½1ð¹1+ð›½2ð¹2+ð›½3ð¹3+ð‘’ : Fit linear model to find the betas for the 3 factors chosen\n",
    "# Fit Multi Factor Linear Regression model using Macroeconomic factors as X and stock returns as y\n",
    "# apple_returns = (\n",
    "#     (portfolio_data[\"AAPL\"] / portfolio_data[\"AAPL\"].shift(1))-1).dropna().tolist()\n",
    "# google_returns = (\n",
    "#     (portfolio_data[\"GOOGL\"] / portfolio_data[\"GOOGL\"].shift(1))-1).dropna().tolist()\n",
    "\n",
    "# print(f\"APPLE RETURNS: {apple_returns[0:10]}\")\n",
    "# print(f\"GOOGLE RETURNS: {google_returns[0:10]}\")\n",
    "\n",
    "returns = {}\n",
    "future_returns = {}\n",
    "for ticker in tickers:\n",
    "    stock_returns = ((portfolio_data[ticker] / portfolio_data[ticker].shift(1))-1).dropna().tolist()\n",
    "    returns[ticker] = stock_returns\n",
    "    \n",
    "    single_index_reg = Ridge()\n",
    "    single_index_reg.fit(factor_returns, stock_returns)\n",
    "    stock_future = single_index_reg.predict(future_factors)\n",
    "    future_returns[ticker] = stock_future\n",
    "    print(\"Coefficients: \", single_index_reg.coef_)\n",
    "\n",
    "\n",
    "# single_index_reg = Ridge()\n",
    "# single_index_reg.fit(factor_returns, apple_returns)\n",
    "# apple_future = single_index_reg.predict(future_factors)\n",
    "# print(\"Coefficients for Apple stock: \", single_index_reg.coef_)\n",
    "\n",
    "# single_index_reg = Ridge()\n",
    "# single_index_reg.fit(factor_returns, google_returns)\n",
    "# google_future = single_index_reg.predict(\n",
    "#     future_factors)\n",
    "# print(\"Coefficients for Google stock: \", single_index_reg.coef_)\n",
    "\n",
    "# future_returns = {'apple': apple_future, 'google': google_future}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(list(zip(apple,google)))\n",
    "future_returns = pd.DataFrame(future_returns)\n",
    "print(future_returns)\n",
    "\n",
    "S = risk_models.sample_cov(future_returns)\n",
    "print(S)\n",
    "# S = risk_models.CovarianceShrinkage(future_returns).ledoit_wolf()\n",
    "# plotting.plot_covariance(S, plot_correlation=True)\n",
    "# You don't have to provide expected returns in this case\n",
    "\n",
    "print(future_returns.mean())\n",
    "ef = EfficientFrontier(future_returns.mean(), S)\n",
    "# ef.min_volatility()\n",
    "# weights = ef.clean_weights()\n",
    "# print(weights)\n",
    "weights = ef.max_sharpe(risk_free_rate=0.0)\n",
    "cleaned_weights = ef.clean_weights()\n",
    "print(cleaned_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "029fb15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected annual return: 0.0018308891149965197\n",
      "Annual volatility: 0.22483001293925864\n",
      "Sharpe ratio: 0.008143437306527057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/efficient_frontier/efficient_frontier.py:441: UserWarning: The risk_free_rate provided to portfolio_performance is different to the one used by max_sharpe. Using the previous value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ret, volatility, sharpe_ratio = ef.portfolio_performance()\n",
    "print(\"Expected annual return:\", ret)\n",
    "print(\"Annual volatility:\", volatility)\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dccb95",
   "metadata": {},
   "source": [
    "### Equity valuation model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea01344",
   "metadata": {},
   "source": [
    "### Black Litterman model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c980fa0",
   "metadata": {},
   "source": [
    "### Algorithmic trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9cefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import talib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "apple_prices = apple_data['Close']\n",
    "\n",
    "# Calculate Bollinger Bands for Apple\n",
    "apple_bb_upper, apple_bb_middle, apple_bb_lower = talib.BBANDS(\n",
    "    apple_prices, timeperiod=20)\n",
    "\n",
    "\n",
    "# Calculate the Bollinger Bands percentages for Apple\n",
    "apple_bb_percentage = (apple_prices - apple_bb_lower) / \\\n",
    "    (apple_bb_upper - apple_bb_lower)\n",
    "\n",
    "# # Combine the Bollinger Bands percentages into a single DataFrame\n",
    "# bb_percentages = pd.concat(\n",
    "#     [apple_bb_percentage, google_bb_percentage], axis=1).dropna()\n",
    "\n",
    "# Define the features and target variable for the machine learning model\n",
    "# Independent variables (Bollinger Bands percentages for the past period)\n",
    "X = apple_bb_percentage.values[:-1]\n",
    "# Target variable (-1 for sell, 1 for buy)\n",
    "y = np.where(apple_prices.values[1:] > apple_bb_upper[:-1], -1, 1)\n",
    "\n",
    "# Train a machine learning model using random forest classifier\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Use the trained model to predict the trading signals for the testing set\n",
    "# Ideally this will be your real time stock prices\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Perform algorithmic trading based on the predicted signals (example logic)\n",
    "capital = 100000  # Initial capital in USD\n",
    "position = 0  # Current position (0 for neutral, 1 for long, -1 for short)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == 1 and position != 1:  # Buy signal\n",
    "        position = 1\n",
    "        # Place a buy order based on your trading platform's API or logic\n",
    "\n",
    "    elif y_pred[i] == -1 and position != -1:  # Sell signal\n",
    "        position = -1\n",
    "        # Place a sell order based on your trading platform's API or logic\n",
    "\n",
    "    elif y_pred[i] == 0 and position != 0:  # Exit position\n",
    "        position = 0\n",
    "        # Close the existing position based on your trading platform's API or logic\n",
    "\n",
    "# Calculate the final capital after the trading period\n",
    "final_capital = capital  # Assume no transaction costs or slippage\n",
    "# Calculate the final capital based on your trading platform's API or logic\n",
    "\n",
    "print(\"Final Capital:\", final_capital)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ffc813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
