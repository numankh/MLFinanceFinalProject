{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c3d512f",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576833bf",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3698336",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using the following machine learning models for making predictions for the following portfolio optimization models:\n",
    "- Mean-variance optimization (chapter 7 of Bodie, Investment book)\n",
    "- Index model (chapter 8 of Bodie, Investment book)\n",
    "- Capital asset pricing model (chapter 9 of Bodie, Investment book)\n",
    "- Arbitrage pricing theory and multifactor model (chapter 10 of Bodie,\n",
    "Investment book)\n",
    "- Equity valuation model (chapter 18 of Bodie, Investment book)\n",
    "- Black Litterman model (chapter 24 of Bodie, Investment book)\n",
    "- Algorithmic trading (this could be restricted to the last month)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5455474e",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40e998cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  10 of 10 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>BRK-B</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>META</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>UNH</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-06-26</th>\n",
       "      <td>185.270004</td>\n",
       "      <td>127.330002</td>\n",
       "      <td>334.119995</td>\n",
       "      <td>118.339996</td>\n",
       "      <td>278.470001</td>\n",
       "      <td>328.600006</td>\n",
       "      <td>406.320007</td>\n",
       "      <td>241.050003</td>\n",
       "      <td>479.059998</td>\n",
       "      <td>104.290001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-27</th>\n",
       "      <td>188.059998</td>\n",
       "      <td>129.179993</td>\n",
       "      <td>335.339996</td>\n",
       "      <td>118.330002</td>\n",
       "      <td>287.049988</td>\n",
       "      <td>334.570007</td>\n",
       "      <td>418.760010</td>\n",
       "      <td>250.210007</td>\n",
       "      <td>482.559998</td>\n",
       "      <td>104.550003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28</th>\n",
       "      <td>189.250000</td>\n",
       "      <td>129.039993</td>\n",
       "      <td>334.149994</td>\n",
       "      <td>120.180000</td>\n",
       "      <td>285.290009</td>\n",
       "      <td>335.850006</td>\n",
       "      <td>411.170013</td>\n",
       "      <td>256.239990</td>\n",
       "      <td>474.450012</td>\n",
       "      <td>105.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29</th>\n",
       "      <td>189.589996</td>\n",
       "      <td>127.900002</td>\n",
       "      <td>336.910004</td>\n",
       "      <td>119.099998</td>\n",
       "      <td>281.529999</td>\n",
       "      <td>335.049988</td>\n",
       "      <td>408.220001</td>\n",
       "      <td>257.500000</td>\n",
       "      <td>476.440002</td>\n",
       "      <td>106.699997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>193.970001</td>\n",
       "      <td>130.360001</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>119.699997</td>\n",
       "      <td>286.980011</td>\n",
       "      <td>340.540009</td>\n",
       "      <td>423.019989</td>\n",
       "      <td>261.769989</td>\n",
       "      <td>480.640015</td>\n",
       "      <td>107.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AAPL        AMZN       BRK-B       GOOGL        META  \\\n",
       "Date                                                                     \n",
       "2023-06-26  185.270004  127.330002  334.119995  118.339996  278.470001   \n",
       "2023-06-27  188.059998  129.179993  335.339996  118.330002  287.049988   \n",
       "2023-06-28  189.250000  129.039993  334.149994  120.180000  285.290009   \n",
       "2023-06-29  189.589996  127.900002  336.910004  119.099998  281.529999   \n",
       "2023-06-30  193.970001  130.360001  341.000000  119.699997  286.980011   \n",
       "\n",
       "                  MSFT        NVDA        TSLA         UNH         XOM  \n",
       "Date                                                                    \n",
       "2023-06-26  328.600006  406.320007  241.050003  479.059998  104.290001  \n",
       "2023-06-27  334.570007  418.760010  250.210007  482.559998  104.550003  \n",
       "2023-06-28  335.850006  411.170013  256.239990  474.450012  105.400002  \n",
       "2023-06-29  335.049988  408.220001  257.500000  476.440002  106.699997  \n",
       "2023-06-30  340.540009  423.019989  261.769989  480.640015  107.250000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "from pypfopt import plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from pypfopt import expected_returns, risk_models, EfficientFrontier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "tickers = [\"AAPL\", \"AMZN\", \"BRK-B\", \"GOOGL\", \"META\", \"MSFT\", \"NVDA\", \"TSLA\", \"UNH\", \"XOM\"]\n",
    "portfolio_data = yf.download(tickers, period=\"5y\")\n",
    "portfolio_data = portfolio_data[\"Adj Close\"]\n",
    "portfolio_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "937b3971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2023-06-26    4328.819824\n",
       "2023-06-27    4378.410156\n",
       "2023-06-28    4376.859863\n",
       "2023-06-29    4396.439941\n",
       "2023-06-30    4450.379883\n",
       "Name: Adj Close, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_index_ticker = \"^GSPC\"  # S&P 500 index\n",
    "market_index_data = yf.download(market_index_ticker, period=\"5y\")\n",
    "market_index_data = market_index_data[\"Adj Close\"]\n",
    "market_index_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c777d4",
   "metadata": {},
   "source": [
    "## Mean Variance Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0515cab1",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88edd1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_prices = {}\n",
    "for ticker in tickers:\n",
    "    data = portfolio_data[ticker].tolist()\n",
    "    # Dependent variable - 10 consecutive days of stock prices\n",
    "    dev_x = [data[i:i+10] for i in range(len(data)-20)]\n",
    "    \n",
    "    # Independent variable - stock price 10th day into the future\n",
    "    dev_y = [data[i+10] for i in range(10,len(data)-10)]\n",
    "    \n",
    "    test = [data[i:i+10] for i in range(len(data)-20,len(data)-10)]\n",
    "    \n",
    "    reg = RandomForestRegressor()\n",
    "    reg.fit(dev_x,dev_y)\n",
    "    \n",
    "    # Predict stock price for 10 future days\n",
    "    pred = reg.predict(test)\n",
    "    future_prices[ticker] = pred\n",
    "\n",
    "future_prices = pd.DataFrame(future_prices)\n",
    "# Construct covariance matrix of future stock prices\n",
    "S = risk_models.CovarianceShrinkage(future_prices).ledoit_wolf()\n",
    "\n",
    "# Use capm to find expected returns on future prices\n",
    "mu = expected_returns.capm_return(future_prices)\n",
    "print(mu)\n",
    "\n",
    "# Do mean variance optimization using efficient frontier\n",
    "ef = EfficientFrontier(mu, S)\n",
    "ef.min_volatility()\n",
    "weights = ef.clean_weights()\n",
    "print(weights)\n",
    "# weights = ef.max_sharpe(risk_free_rate=0.02)\n",
    "# cleaned_weights = ef.clean_weights()\n",
    "# print(cleaned_weights)\n",
    "\n",
    "ret, volatility, sharpe_ratio = ef.portfolio_performance()\n",
    "print(\"Expected annual return:\", ret)\n",
    "print(\"Annual volatility:\", volatility)\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd90b9",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13084abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_prices = {}\n",
    "for ticker in tickers:\n",
    "    data = portfolio_data[ticker].tolist()\n",
    "    dev_x = [data[i:i+10] for i in range(len(data)-20)]\n",
    "    dev_y = [data[i+10] for i in range(10, len(data)-10)]\n",
    "    test = [data[i:i+10] for i in range(len(data)-20, len(data)-10)]\n",
    "    \n",
    "    reg = SVR()\n",
    "    reg.fit(dev_x, dev_y)\n",
    "    \n",
    "    pred = reg.predict(test)\n",
    "    future_prices[ticker] = pred\n",
    "\n",
    "future_prices = pd.DataFrame(future_prices)\n",
    "\n",
    "S = risk_models.CovarianceShrinkage(future_prices).ledoit_wolf()\n",
    "mu = expected_returns.capm_return(future_prices)\n",
    "print(mu)\n",
    "\n",
    "ef = EfficientFrontier(mu, S)\n",
    "ef.min_volatility()\n",
    "weights = ef.clean_weights()\n",
    "print(weights)\n",
    "\n",
    "\n",
    "ret, volatility, sharpe_ratio = ef.portfolio_performance()\n",
    "print(\"Expected annual return:\", ret)\n",
    "print(\"Annual volatility:\", volatility)\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894acc7c",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbad704",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_prices = {}\n",
    "for ticker in tickers:\n",
    "    data = portfolio_data[ticker].tolist()\n",
    "    dev_x = [data[i:i+10] for i in range(len(data)-20)]\n",
    "    dev_y = [data[i+10] for i in range(10, len(data)-10)]\n",
    "    test = [data[i:i+10] for i in range(len(data)-20, len(data)-10)]\n",
    "    \n",
    "    reg = MLPRegressor(hidden_layer_sizes=(100,100), random_state=42)  # You can adjust the hidden_layer_sizes and other parameters as needed\n",
    "    reg.fit(dev_x, dev_y)\n",
    "    \n",
    "    pred = reg.predict(test)\n",
    "    future_prices[ticker] = pred\n",
    "\n",
    "future_prices = pd.DataFrame(future_prices)\n",
    "\n",
    "S = risk_models.CovarianceShrinkage(future_prices).ledoit_wolf()\n",
    "mu = expected_returns.capm_return(future_prices)\n",
    "print(mu)\n",
    "\n",
    "ef = EfficientFrontier(mu, S)\n",
    "ef.min_volatility()\n",
    "weights = ef.clean_weights()\n",
    "print(weights)\n",
    "\n",
    "ret, volatility, sharpe_ratio = ef.portfolio_performance()\n",
    "print(\"Expected annual return:\", ret)\n",
    "print(\"Annual volatility:\", volatility)\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e43441",
   "metadata": {},
   "source": [
    "## Index model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleIndexModel:\n",
    "    def __init__(self, tickers, market_index_data, portfolio_data, reg_model):\n",
    "        self.tickers = tickers\n",
    "        self.market_index_data = market_index_data\n",
    "        self.portfolio_data = portfolio_data\n",
    "        self.reg_model = reg_model\n",
    "        self.returns = {}\n",
    "        self.beta = {}\n",
    "        self.alpha = {}\n",
    "        self.residual_variance = {}\n",
    "\n",
    "    def calculate_returns(self):\n",
    "        # Returns of stocks and market\n",
    "        self.returns = {\"MARKET\": ((self.market_index_data / self.market_index_data.shift(1)) - 1).dropna().tolist()}\n",
    "        for ticker in self.tickers:\n",
    "            self.returns[ticker] = ((self.portfolio_data[ticker] / self.portfolio_data[ticker].shift(1))-1).dropna().tolist()\n",
    "\n",
    "    def fit_regression(self):\n",
    "        # Forecast market\n",
    "        market_x = [self.returns[\"MARKET\"][i:i+10] for i in range(len(self.returns[\"MARKET\"])-20)]\n",
    "        market_y = [self.returns[\"MARKET\"][i+10] for i in range(10, len(self.returns[\"MARKET\"])-10)]\n",
    "        market_test = [self.returns[\"MARKET\"][i:i+10] \n",
    "                       for i in range(len(self.returns[\"MARKET\"])-20, len(self.returns[\"MARKET\"])-10)]\n",
    "\n",
    "        reg = self.reg_model\n",
    "        reg.fit(market_x, market_y)\n",
    "        market_future = reg.predict(market_test)\n",
    "\n",
    "        # Forecast each stock\n",
    "        for ticker in self.tickers:\n",
    "            stock_x = [self.returns[ticker][i:i+10] for i in range(len(self.returns[ticker])-20)]\n",
    "            stock_y = [self.returns[ticker][i+10] for i in range(10, len(self.returns[ticker])-10)]\n",
    "            stock_test = [self.returns[ticker][i:i+10]\n",
    "                          for i in range(len(self.returns[ticker])-20, len(self.returns[ticker])-10)]\n",
    "\n",
    "            reg = self.reg_model\n",
    "            reg.fit(stock_x, stock_y)\n",
    "            stock_future = reg.predict(stock_test)\n",
    "\n",
    "            single_index_reg = LinearRegression()\n",
    "            single_index_reg.fit(np.array(market_future).reshape(-1, 1), y=stock_future)\n",
    "\n",
    "            self.beta[ticker] = single_index_reg.coef_[0]\n",
    "            self.alpha[ticker] = single_index_reg.intercept_\n",
    "\n",
    "            y_pred = single_index_reg.predict(np.array(self.returns[\"MARKET\"]).reshape(-1, 1))\n",
    "            residuals = self.returns[ticker] - y_pred\n",
    "            self.residual_variance[ticker] = np.var(residuals)\n",
    "\n",
    "    def optimize_portfolio(self):\n",
    "        # Compute the initial position of each security\n",
    "        weights = {ticker: self.alpha[ticker] / self.residual_variance[ticker] for ticker in self.tickers}\n",
    "        total_weight = sum(weights.values())\n",
    "        weights = {ticker: weight / total_weight for ticker, weight in weights.items()}\n",
    "\n",
    "        # Compute the alpha of the active portfolio\n",
    "        alpha_portfolio = sum(weights[ticker] * self.alpha[ticker] for ticker in self.tickers)\n",
    "\n",
    "        # Compute the residual variance of the active portfolio\n",
    "        residual_variance_portfolio = sum((weights[ticker] ** 2) * self.residual_variance[ticker] for ticker in self.tickers)\n",
    "\n",
    "        # Compute the initial position in the active portfolio\n",
    "        residual_variance_market = 0.0114  # Variance of S&P 500\n",
    "        risk_premium_market = 0.056\n",
    "        initial_position_portfolio = (alpha_portfolio * residual_variance_market) / (residual_variance_portfolio * risk_premium_market)\n",
    "\n",
    "        # Compute the beta of the active portfolio\n",
    "        beta_portfolio = sum(weights[ticker] * self.beta[ticker] for ticker in self.tickers)\n",
    "\n",
    "        # Adjust the initial position in the active portfolio\n",
    "        adjusted_position_portfolio = initial_position_portfolio / (1 + (1 - beta_portfolio) * initial_position_portfolio)\n",
    "\n",
    "        # Optimal risky portfolio now has weights\n",
    "        final_weight_market = 1 - adjusted_position_portfolio\n",
    "        weights = {ticker: weight * adjusted_position_portfolio for ticker, weight in weights.items()}\n",
    "\n",
    "        # Calculate the risk premium of the portfolio\n",
    "        risk_premium_portfolio = (final_weight_market + adjusted_position_portfolio * beta_portfolio) * risk_premium_market + adjusted_position_portfolio * alpha_portfolio\n",
    "\n",
    "        # Compute the variance of the portfolio\n",
    "        portfolio_variance = (final_weight_market + adjusted_position_portfolio * beta_portfolio) ** 2 * residual_variance_market + adjusted_position_portfolio ** 2 * residual_variance_portfolio\n",
    "\n",
    "        # Calculate the Sharpe ratio\n",
    "        sharpe_ratio = risk_premium_portfolio / (portfolio_variance ** 0.5)\n",
    "\n",
    "        return weights, final_weight_market, sharpe_ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdc52d5",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c642ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = RandomForestRegressor()\n",
    "portfolio = SingleIndexModel(tickers, market_index_data, portfolio_data, reg_model)\n",
    "portfolio.calculate_returns()\n",
    "portfolio.fit_regression()\n",
    "weights, final_weight_market, sharpe_ratio = portfolio.optimize_portfolio()\n",
    "print(\"------------------------------\")\n",
    "print(\"Final Weights:\")\n",
    "print(\"Weight Market S&P:\", final_weight_market)\n",
    "print(f\"Weights: {weights}\")\n",
    "print(\"------------------------------\")\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa76324",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b45800",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = SVR()\n",
    "portfolio = SingleIndexModel(tickers, market_index_data, portfolio_data, reg_model)\n",
    "portfolio.calculate_returns()\n",
    "portfolio.fit_regression()\n",
    "weights, final_weight_market, sharpe_ratio = portfolio.optimize_portfolio()\n",
    "print(\"------------------------------\")\n",
    "print(\"Final Weights:\")\n",
    "print(\"Weight Market S&P:\", final_weight_market)\n",
    "print(f\"Weights: {weights}\")\n",
    "print(\"------------------------------\")\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8fade6",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e57a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = MLPRegressor(hidden_layer_sizes=(100,100))\n",
    "portfolio = SingleIndexModel(tickers, market_index_data, portfolio_data, reg_model)\n",
    "portfolio.calculate_returns()\n",
    "portfolio.fit_regression()\n",
    "weights, final_weight_market, sharpe_ratio = portfolio.optimize_portfolio()\n",
    "print(\"------------------------------\")\n",
    "print(\"Final Weights:\")\n",
    "print(\"Weight Market S&P:\", final_weight_market)\n",
    "print(f\"Weights: {weights}\")\n",
    "print(\"------------------------------\")\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db4f9d8",
   "metadata": {},
   "source": [
    "### Capital asset pricing model (CAPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b915a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = {\"MARKET\": ((market_index_data / market_index_data.shift(1)) - 1).dropna().tolist()}\n",
    "for ticker in tickers:\n",
    "    returns[ticker] = ((portfolio_data[ticker] / portfolio_data[ticker].shift(1))-1).dropna().tolist()\n",
    "\n",
    "print(returns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482e4ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_x = [returns[\"MARKET\"][i:i+10] for i in range(len(returns[\"MARKET\"])-20)]\n",
    "market_y = [returns[\"MARKET\"][i+10] for i in range(10, len(returns[\"MARKET\"])-10)]\n",
    "market_test = [returns[\"MARKET\"][i:i+10]\n",
    "               for i in range(len(returns[\"MARKET\"])-20, len(returns[\"MARKET\"])-10)]\n",
    "\n",
    "reg = MLPRegressor(hidden_layer_sizes=(100,100))\n",
    "reg.fit(market_x, market_y)\n",
    "market_future = reg.predict(market_test)\n",
    "print(market_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca74a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_returns = {}\n",
    "for ticker in tickers:\n",
    "    single_index_reg = Ridge()\n",
    "    single_index_reg.fit(np.array(returns[\"MARKET\"]).reshape(-1, 1), y=returns[ticker])\n",
    "    future_returns[ticker] = single_index_reg.predict(np.array(market_future).reshape(-1, 1))\n",
    "\n",
    "future_returns = pd.DataFrame(future_returns)\n",
    "print(future_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94933acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = risk_models.sample_cov(future_returns)\n",
    "S = risk_models.CovarianceShrinkage(future_returns).ledoit_wolf()\n",
    "plotting.plot_covariance(S, plot_correlation=True)\n",
    "# You don't have to provide expected returns in this case\n",
    "\n",
    "\n",
    "ef = EfficientFrontier(None, S)\n",
    "ef.min_volatility()\n",
    "weights = ef.clean_weights()\n",
    "print(weights)\n",
    "# weights = ef.max_sharpe(risk_free_rate=-0.2)\n",
    "# cleaned_weights = ef.clean_weights()\n",
    "# print(cleaned_weights)\n",
    "# print(mu)\n",
    "\n",
    "ret, volatility, sharpe_ratio = ef.portfolio_performance()\n",
    "print(\"Expected annual return:\", ret)\n",
    "print(\"Annual volatility:\", volatility)\n",
    "print(\"Sharpe ratio:\", sharpe_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e78f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt import expected_returns\n",
    "from pypfopt import plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from pypfopt import expected_returns, risk_models, EfficientFrontier\n",
    "\n",
    "# T-bill rate\n",
    "risk_free_rate = 0.01\n",
    "\n",
    "# apple_returns = (\n",
    "#     (portfolio_data[\"AAPL\"] / portfolio_data[\"AAPL\"].shift(1))-1-risk_free_rate).dropna().tolist()\n",
    "# google_returns = (\n",
    "#     (portfolio_data[\"GOOGL\"] / portfolio_data[\"GOOGL\"].shift(1))-1-risk_free_rate).dropna().tolist()\n",
    "# market_returns = (\n",
    "#     (market_index_data / market_index_data.shift(1))-1-risk_free_rate).dropna().tolist()\n",
    "\n",
    "# returns = {\"MARKET\": ((market_index_data / market_index_data.shift(1)) - 1).dropna().tolist()}\n",
    "# for ticker in self.tickers:\n",
    "#     returns[ticker] = ((portfolio_data[ticker] / portfolio_data[ticker].shift(1))-1).dropna().tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# apple_prices = apple_data['Close'].tolist()\n",
    "# google_prices = google_data['Close'].tolist()\n",
    "market_x = [returns[\"MARKET\"][i:i+10] for i in range(len(returns[\"MARKET\"])-20)]\n",
    "market_y = [returns[\"MARKET\"][i+10] for i in range(10, len(returns[\"MARKET\"])-10)]\n",
    "market_test = [returns[\"MARKET\"][i:i+10]\n",
    "               for i in range(len(returns[\"MARKET\"])-20, len(returns[\"MARKET\"])-10)]\n",
    "\n",
    "# reg = MLPRegressor(hidden_layer_sizes=(100,100))\n",
    "# reg = SVR()\n",
    "reg = RandomForestRegressor()\n",
    "\n",
    "reg.fit(market_x, market_y)\n",
    "market_future = reg.predict(market_test)\n",
    "\n",
    "# print(market_future)\n",
    "\n",
    "single_index_reg = Ridge()\n",
    "single_index_reg.fit(np.array(market_returns).reshape(-1, 1), y=apple_returns)\n",
    "apple_future = single_index_reg.predict(np.array(market_future).reshape(-1, 1))\n",
    "\n",
    "single_index_reg = Ridge()\n",
    "single_index_reg.fit(np.array(market_returns).reshape(-1, 1), google_returns)\n",
    "google_future = single_index_reg.predict(\n",
    "    np.array(market_future).reshape(-1, 1))\n",
    "\n",
    "future_returns = {'apple': apple_future, 'google': google_future}\n",
    "future_returns = pd.DataFrame(future_returns)\n",
    "\n",
    "print(future_returns)\n",
    "\n",
    "S = risk_models.sample_cov(future_returns)\n",
    "# S = risk_models.CovarianceShrinkage(future_returns).ledoit_wolf()\n",
    "# plotting.plot_covariance(S, plot_correlation=True)\n",
    "# You don't have to provide expected returns in this case\n",
    "\n",
    "\n",
    "ef = EfficientFrontier(None, S)\n",
    "ef.min_volatility()\n",
    "weights = ef.clean_weights()\n",
    "print(weights)\n",
    "# weights = ef.max_sharpe(risk_free_rate=-0.2)\n",
    "# cleaned_weights = ef.clean_weights()\n",
    "# print(cleaned_weights)\n",
    "# print(mu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a626fe31",
   "metadata": {},
   "source": [
    "### Arbitrage pricing theory and multifactor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a133b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_models = [RandomForestRegressor(), GradientBoostingRegressor(), MLPRegressor(hidden_layer_sizes=(100, 100))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8884ea50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "[*********************100%***********************]  3 of 3 completed\n",
      "OrderedDict([('AAPL', 0.0), ('AMZN', 0.0), ('BRK-B', 0.0), ('GOOGL', 0.0), ('META', 0.0), ('MSFT', 0.0), ('NVDA', 0.64698), ('TSLA', 0.33899), ('UNH', 0.01403), ('XOM', 0.0)])\n",
      "Expected annual return: 0.0013009960816877675\n",
      "Annual volatility: 0.20980700238081074\n",
      "Sharpe ratio: 0.006200918305511992\n",
      "GradientBoostingRegressor()\n",
      "[                       0%                       ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/risk_models.py:70: UserWarning: The covariance matrix is non positive semidefinite. Amending eigenvalues.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/risk_models.py:89: UserWarning: Could not fix matrix. Please try a different risk model.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/efficient_frontier/efficient_frontier.py:441: UserWarning: The risk_free_rate provided to portfolio_performance is different to the one used by max_sharpe. Using the previous value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed\n",
      "OrderedDict([('AAPL', 0.0), ('AMZN', 0.02168), ('BRK-B', 0.0), ('GOOGL', 0.0), ('META', 0.1129), ('MSFT', 0.0), ('NVDA', 0.05004), ('TSLA', 0.2058), ('UNH', 0.0), ('XOM', 0.60958)])\n",
      "Expected annual return: 0.0012204178677343116\n",
      "Annual volatility: 0.8635515801904234\n",
      "Sharpe ratio: 0.0014132541653912496\n",
      "MLPRegressor(hidden_layer_sizes=(100, 100))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/efficient_frontier/efficient_frontier.py:441: UserWarning: The risk_free_rate provided to portfolio_performance is different to the one used by max_sharpe. Using the previous value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed\n",
      "OrderedDict([('AAPL', 0.0), ('AMZN', 0.0), ('BRK-B', 0.0), ('GOOGL', 0.0), ('META', 0.0), ('MSFT', 0.0), ('NVDA', 0.0), ('TSLA', 0.20645), ('UNH', 0.0), ('XOM', 0.79355)])\n",
      "Expected annual return: 0.0016299358607353295\n",
      "Annual volatility: 0.4156018295359954\n",
      "Sharpe ratio: 0.003921868829487817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/risk_models.py:70: UserWarning: The covariance matrix is non positive semidefinite. Amending eigenvalues.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/risk_models.py:89: UserWarning: Could not fix matrix. Please try a different risk model.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/pypfopt/efficient_frontier/efficient_frontier.py:441: UserWarning: The risk_free_rate provided to portfolio_performance is different to the one used by max_sharpe. Using the previous value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for reg in reg_models:\n",
    "    print(reg)\n",
    "    # Example tickers for S&P 500, and 20+ Year Treasury Bond ETFs\n",
    "    factor_tickers = ['SPY', 'TLT', 'BND']\n",
    "\n",
    "    # Fetch historical data for the macroeconomic factors S&P and Treasury Bond\n",
    "    factor_data = yf.download(factor_tickers, period=\"5y\")\n",
    "    factor_data = factor_data['Adj Close']\n",
    "\n",
    "    # Calculate the returns for the S&P and Treasury bond factors\n",
    "    factor_returns = factor_data.pct_change().dropna()\n",
    "    spy_returns = factor_returns['SPY']\n",
    "    tlt_returns = factor_returns['TLT']\n",
    "    bnd_returns = factor_returns['BND']\n",
    "\n",
    "    # FACTOR 1\n",
    "    # Train ML model to predict future price of S&P market factors\n",
    "    bnd_x = [bnd_returns[i:i+10] for i in range(len(bnd_returns)-20)]\n",
    "    bnd_y = [bnd_returns[i+10] for i in range(10, len(bnd_returns)-10)]\n",
    "\n",
    "    bnd_test = [bnd_returns[i:i+10]\n",
    "                   for i in range(len(bnd_returns)-20, len(bnd_returns)-10)]\n",
    "    reg.fit(bnd_x, bnd_y)\n",
    "    bnd_future = reg.predict(bnd_test)\n",
    "\n",
    "    # FACTOR 2\n",
    "    # Train ML model to predict future price of S&P market factors\n",
    "    spy_x = [spy_returns[i:i+10] for i in range(len(spy_returns)-20)]\n",
    "    spy_y = [spy_returns[i+10] for i in range(10, len(spy_returns)-10)]\n",
    "\n",
    "    spy_test = [spy_returns[i:i+10]\n",
    "                   for i in range(len(spy_returns)-20, len(spy_returns)-10)]\n",
    "    reg.fit(spy_x, spy_y)\n",
    "    spy_future = reg.predict(spy_test)\n",
    "\n",
    "    # FACTOR 3\n",
    "    # Train ML model to predict future price of Treasury Bond ETF factors\n",
    "    tlt_x = [tlt_returns[i:i+10] for i in range(len(tlt_returns)-20)]\n",
    "    tlt_y = [tlt_returns[i+10] for i in range(10, len(tlt_returns)-10)]\n",
    "\n",
    "    tlt_test = [tlt_returns[i:i+10]\n",
    "                   for i in range(len(tlt_returns)-20, len(tlt_returns)-10)]\n",
    "\n",
    "    reg.fit(tlt_x, tlt_y)\n",
    "    tlt_future = reg.predict(tlt_test)\n",
    "\n",
    "    # FACTOR 4\n",
    "    # GDP Price of USA for past 5 years\n",
    "\n",
    "    # US GDP per capita Prices of last 5 years\n",
    "    GDP_prices = {\n",
    "            2018: 59607,\n",
    "            2019: 60698,\n",
    "            2020: 58453,\n",
    "            2021: 61855,\n",
    "            2022: 62551,\n",
    "            2023: 63451 # Forecast data also available online\n",
    "        }\n",
    "\n",
    "    # Normalize the GDP values as it will make the other factors irrelevant as it is very large\n",
    "    values = list(GDP_prices.values())\n",
    "    values_array = [[value] for value in values]\n",
    "    scaler = StandardScaler()\n",
    "    scaled_values = scaler.fit_transform(values_array)\n",
    "    scaled_values = scaled_values.flatten()\n",
    "    scaled_GDP_prices = {year: scaled_value for year, scaled_value in zip(GDP_prices.keys(), scaled_values)}\n",
    "\n",
    "    # print(scaled_GDP_prices)\n",
    "\n",
    "    for index, row in factor_returns.iterrows():\n",
    "        # Extract the year from the date\n",
    "        year = index.year\n",
    "\n",
    "        # Fill the 'GDP' column with the corresponding GDP price based on the year\n",
    "        factor_returns.at[index, 'GDP'] = scaled_GDP_prices.get(year)\n",
    "\n",
    "    future_factors = {'BND': bnd_future, 'SPY': spy_future, 'TLT': tlt_future, 'GDP': [scaled_GDP_prices.get(2023)]*10}\n",
    "    future_factors = pd.DataFrame(future_factors)\n",
    "\n",
    "    returns = {}\n",
    "    future_returns = {}\n",
    "    for ticker in tickers:\n",
    "        stock_returns = ((portfolio_data[ticker] / portfolio_data[ticker].shift(1))-1).dropna().tolist()\n",
    "        returns[ticker] = stock_returns\n",
    "\n",
    "        single_index_reg = Ridge()\n",
    "        single_index_reg.fit(factor_returns, stock_returns)\n",
    "        stock_future = single_index_reg.predict(future_factors)\n",
    "        future_returns[ticker] = stock_future\n",
    "    #     print(\"Coefficients: \", single_index_reg.coef_)\n",
    "\n",
    "    future_returns = pd.DataFrame(future_returns)\n",
    "    # print(future_returns)\n",
    "\n",
    "    S = risk_models.sample_cov(future_returns)\n",
    "    # print(S)\n",
    "\n",
    "\n",
    "#     print(future_returns.mean())\n",
    "    ef = EfficientFrontier(future_returns.mean(), S)\n",
    "    weights = ef.max_sharpe(risk_free_rate=0.0)\n",
    "    cleaned_weights = ef.clean_weights()\n",
    "    print(cleaned_weights)\n",
    "\n",
    "    ret, volatility, sharpe_ratio = ef.portfolio_performance()\n",
    "    print(\"Expected annual return:\", ret)\n",
    "    print(\"Annual volatility:\", volatility)\n",
    "    print(\"Sharpe ratio:\", sharpe_ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dccb95",
   "metadata": {},
   "source": [
    "### Equity valuation model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea01344",
   "metadata": {},
   "source": [
    "### Black Litterman model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c980fa0",
   "metadata": {},
   "source": [
    "### Algorithmic trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9cefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import talib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "apple_prices = apple_data['Close']\n",
    "\n",
    "# Calculate Bollinger Bands for Apple\n",
    "apple_bb_upper, apple_bb_middle, apple_bb_lower = talib.BBANDS(\n",
    "    apple_prices, timeperiod=20)\n",
    "\n",
    "\n",
    "# Calculate the Bollinger Bands percentages for Apple\n",
    "apple_bb_percentage = (apple_prices - apple_bb_lower) / \\\n",
    "    (apple_bb_upper - apple_bb_lower)\n",
    "\n",
    "# # Combine the Bollinger Bands percentages into a single DataFrame\n",
    "# bb_percentages = pd.concat(\n",
    "#     [apple_bb_percentage, google_bb_percentage], axis=1).dropna()\n",
    "\n",
    "# Define the features and target variable for the machine learning model\n",
    "# Independent variables (Bollinger Bands percentages for the past period)\n",
    "X = apple_bb_percentage.values[:-1]\n",
    "# Target variable (-1 for sell, 1 for buy)\n",
    "y = np.where(apple_prices.values[1:] > apple_bb_upper[:-1], -1, 1)\n",
    "\n",
    "# Train a machine learning model using random forest classifier\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Use the trained model to predict the trading signals for the testing set\n",
    "# Ideally this will be your real time stock prices\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Perform algorithmic trading based on the predicted signals (example logic)\n",
    "capital = 100000  # Initial capital in USD\n",
    "position = 0  # Current position (0 for neutral, 1 for long, -1 for short)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == 1 and position != 1:  # Buy signal\n",
    "        position = 1\n",
    "        # Place a buy order based on your trading platform's API or logic\n",
    "\n",
    "    elif y_pred[i] == -1 and position != -1:  # Sell signal\n",
    "        position = -1\n",
    "        # Place a sell order based on your trading platform's API or logic\n",
    "\n",
    "    elif y_pred[i] == 0 and position != 0:  # Exit position\n",
    "        position = 0\n",
    "        # Close the existing position based on your trading platform's API or logic\n",
    "\n",
    "# Calculate the final capital after the trading period\n",
    "final_capital = capital  # Assume no transaction costs or slippage\n",
    "# Calculate the final capital based on your trading platform's API or logic\n",
    "\n",
    "print(\"Final Capital:\", final_capital)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ffc813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
